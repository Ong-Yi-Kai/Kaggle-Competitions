{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "from flaml import AutoML\n",
    "import optuna\n",
    "import pickle\n",
    "import datatable as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, chi2, f_classif\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE LOADING!\n"
     ]
    }
   ],
   "source": [
    "# loading train and test sets\n",
    "#datatables load large datasets faster and more memory efficient\n",
    "train = dt.fread(r\"C:\\Users\\Ong Yi Kai\\Desktop\\Data\\Kaggle competitions\\Tabular Data Oct 2021\\train.csv\").to_pandas()\n",
    "test = dt.fread(r\"C:\\Users\\Ong Yi Kai\\Desktop\\Data\\Kaggle competitions\\Tabular Data Oct 2021\\test.csv\").to_pandas()\n",
    "print('DONE LOADING!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will help to reduce momory \n",
    "# data will be samller with the same value\n",
    "\n",
    "@jit(forceobj=True)\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "        \n",
    "            \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1878.74 MB\n",
      "Memory usage after optimization is: 549.32 MB\n",
      "Decreased by 70.8%\n",
      "Memory usage of dataframe is 938.89 MB\n",
      "Memory usage after optimization is: 273.70 MB\n",
      "Decreased by 70.8%\n"
     ]
    }
   ],
   "source": [
    "#reducing the memory of data types\n",
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate test into ID and Data\n",
    "ID_test = test.iloc[:,:1]\n",
    "X_test = test.iloc[:,1:]\n",
    "#seperate train into features and targets\n",
    "features, target = train.iloc[:,1:-1], train.iloc[:,-1:]\n",
    "#create a validation set\n",
    "X_train, X_train_meta, y_train, y_train_meta = train_test_split(features, target, test_size=0.2, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise features to mean=0,std=1\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(X=X_train,y=y_train)\n",
    "\n",
    "X_train = scaler.transform(X=X_train)\n",
    "X_train_meta = scaler.transform(X=X_train_meta)\n",
    "X_test = scaler.transform(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but SelectKBest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but SelectKBest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but SelectKBest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Univariate feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=150)\n",
    "selector.fit(X=features,y=np.ravel(target))\n",
    "#fit selector on data\n",
    "X_train = selector.transform(X_train)\n",
    "X_train_meta = selector.transform(X_train_meta)\n",
    "X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_train_meta = pd.DataFrame(X_train_meta)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train_meta = pd.DataFrame(y_train_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIGHT GBM!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamters found using optuna from kaggle discussions\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbosity': '-1',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'feature_pre_filter': False,\n",
    "    'lambda_l1': 8.533875942246594,\n",
    "    'lambda_l2': 2.0533270677941314e-06,\n",
    "    'num_leaves': 13,\n",
    "    'feature_fraction': 0.4,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 0,\n",
    "    'min_child_samples': 50,\n",
    "    'early_stopping_round': 100,\n",
    "    'num_iterations':1000\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.847194\n",
      "[200]\tvalid_0's auc: 0.85302\n",
      "[300]\tvalid_0's auc: 0.855288\n",
      "[400]\tvalid_0's auc: 0.856304\n",
      "[500]\tvalid_0's auc: 0.856691\n",
      "[600]\tvalid_0's auc: 0.856903\n",
      "[700]\tvalid_0's auc: 0.85687\n",
      "Early stopping, best iteration is:\n",
      "[633]\tvalid_0's auc: 0.856908\n",
      "auc: 0.856908\n",
      "Fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.847892\n",
      "[200]\tvalid_0's auc: 0.853573\n",
      "[300]\tvalid_0's auc: 0.855818\n",
      "[400]\tvalid_0's auc: 0.856827\n",
      "[500]\tvalid_0's auc: 0.857263\n",
      "[600]\tvalid_0's auc: 0.857408\n",
      "[700]\tvalid_0's auc: 0.857443\n",
      "[800]\tvalid_0's auc: 0.857484\n",
      "[900]\tvalid_0's auc: 0.857465\n",
      "Early stopping, best iteration is:\n",
      "[823]\tvalid_0's auc: 0.857513\n",
      "auc: 0.857513\n",
      "Fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.846142\n",
      "[200]\tvalid_0's auc: 0.8518\n",
      "[300]\tvalid_0's auc: 0.854095\n",
      "[400]\tvalid_0's auc: 0.855177\n",
      "[500]\tvalid_0's auc: 0.855593\n",
      "[600]\tvalid_0's auc: 0.855726\n",
      "[700]\tvalid_0's auc: 0.855732\n",
      "Early stopping, best iteration is:\n",
      "[674]\tvalid_0's auc: 0.855778\n",
      "auc: 0.855778\n",
      "Fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.84609\n",
      "[200]\tvalid_0's auc: 0.85193\n",
      "[300]\tvalid_0's auc: 0.854216\n",
      "[400]\tvalid_0's auc: 0.855317\n",
      "[500]\tvalid_0's auc: 0.855802\n",
      "[600]\tvalid_0's auc: 0.855952\n",
      "[700]\tvalid_0's auc: 0.856024\n",
      "[800]\tvalid_0's auc: 0.855994\n",
      "Early stopping, best iteration is:\n",
      "[702]\tvalid_0's auc: 0.85603\n",
      "auc: 0.856030\n",
      "Fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.846816\n",
      "[200]\tvalid_0's auc: 0.852035\n",
      "[300]\tvalid_0's auc: 0.854032\n",
      "[400]\tvalid_0's auc: 0.854948\n",
      "[500]\tvalid_0's auc: 0.855331\n",
      "[600]\tvalid_0's auc: 0.855501\n",
      "[700]\tvalid_0's auc: 0.855563\n",
      "[800]\tvalid_0's auc: 0.855584\n",
      "[900]\tvalid_0's auc: 0.855595\n",
      "Early stopping, best iteration is:\n",
      "[880]\tvalid_0's auc: 0.855622\n",
      "auc: 0.855622\n",
      "Fold:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.846725\n",
      "[200]\tvalid_0's auc: 0.851948\n",
      "[300]\tvalid_0's auc: 0.854015\n",
      "[400]\tvalid_0's auc: 0.854806\n",
      "[500]\tvalid_0's auc: 0.855164\n",
      "[600]\tvalid_0's auc: 0.855236\n",
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's auc: 0.855247\n",
      "auc: 0.855247\n",
      "Fold:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.846752\n",
      "[200]\tvalid_0's auc: 0.852433\n",
      "[300]\tvalid_0's auc: 0.854652\n",
      "[400]\tvalid_0's auc: 0.85564\n",
      "[500]\tvalid_0's auc: 0.856118\n",
      "[600]\tvalid_0's auc: 0.856261\n",
      "Early stopping, best iteration is:\n",
      "[593]\tvalid_0's auc: 0.856263\n",
      "auc: 0.856263\n",
      "Fold:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.845376\n",
      "[200]\tvalid_0's auc: 0.851306\n",
      "[300]\tvalid_0's auc: 0.853473\n",
      "[400]\tvalid_0's auc: 0.854365\n",
      "[500]\tvalid_0's auc: 0.854756\n",
      "[600]\tvalid_0's auc: 0.854872\n",
      "[700]\tvalid_0's auc: 0.854909\n",
      "[800]\tvalid_0's auc: 0.854868\n",
      "Early stopping, best iteration is:\n",
      "[700]\tvalid_0's auc: 0.854909\n",
      "auc: 0.854909\n",
      "Fold:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.84893\n",
      "[200]\tvalid_0's auc: 0.8543\n",
      "[300]\tvalid_0's auc: 0.856472\n",
      "[400]\tvalid_0's auc: 0.857353\n",
      "[500]\tvalid_0's auc: 0.857753\n",
      "[600]\tvalid_0's auc: 0.857881\n",
      "[700]\tvalid_0's auc: 0.857913\n",
      "[800]\tvalid_0's auc: 0.857873\n",
      "Early stopping, best iteration is:\n",
      "[711]\tvalid_0's auc: 0.857937\n",
      "auc: 0.857937\n",
      "Fold:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.84698\n",
      "[200]\tvalid_0's auc: 0.852686\n",
      "[300]\tvalid_0's auc: 0.854784\n",
      "[400]\tvalid_0's auc: 0.855737\n",
      "[500]\tvalid_0's auc: 0.85607\n",
      "[600]\tvalid_0's auc: 0.856259\n",
      "[700]\tvalid_0's auc: 0.856292\n",
      "Early stopping, best iteration is:\n",
      "[687]\tvalid_0's auc: 0.856303\n",
      "auc: 0.856303\n"
     ]
    }
   ],
   "source": [
    "#create Kfold object\n",
    "#startified fold keeps the proportion of positive and negative targets the same for all splits\n",
    "folds = StratifiedKFold(n_splits=10,random_state=2021,shuffle=True)\n",
    "\n",
    "#create arrays to store and aggregrate predictions after each fold\n",
    "#aggregating to reduce the varian\n",
    "lgb_test_pred = np.zeros(len(test))\n",
    "lgb_train_meta_pred = np.zeros(len(y_train_meta))\n",
    "\n",
    "for fold,(train_idx, val_idx) in enumerate(folds.split(X_train,y_train)):\n",
    "    print(f'Fold:{fold}')\n",
    "    \n",
    "    #create Dataset objects\n",
    "    training = lgb.Dataset(X_train.iloc[train_idx,:], label=y_train.iloc[train_idx,:])\n",
    "    CV = lgb.Dataset(X_train.iloc[val_idx,:], label=y_train.iloc[val_idx,:])\n",
    "    \n",
    "    #create lgbm model object and train\n",
    "    model_lgbm = lgb.train(\n",
    "            lgb_params, \n",
    "            training,\n",
    "            valid_sets=[CV], \n",
    "            verbose_eval=100, \n",
    "            early_stopping_rounds=100)\n",
    "    \n",
    "    #predictions for train_meta and bagging\n",
    "    train_meta_pred_fold = model_lgbm.predict(X_train_meta)\n",
    "    lgb_train_meta_pred =np.column_stack((lgb_train_meta_pred,train_meta_pred_fold)) \n",
    "    \n",
    "    #prediction for test and bagging\n",
    "    test_pred_fold = model_lgbm.predict(X_test)\n",
    "    lgb_test_pred = np.column_stack((lgb_test_pred,test_pred_fold))\n",
    "    \n",
    "    #roc_auc_score using training CV for personal satisfaction XD\n",
    "    cv_pred = model_lgbm.predict(X_train.iloc[val_idx,:])\n",
    "    auc = roc_auc_score(y_train.iloc[val_idx,:],cv_pred)\n",
    "    print(f\"auc: {auc:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters trained by optuna from kaggle discussions\n",
    "cat_params = {'iterations': 2866,\n",
    " 'od_wait': 3385,\n",
    " 'learning_rate': 0.04280810491488757,\n",
    " 'reg_lambda': 0.32139709692279206,\n",
    " 'subsample': 0.8442605943226449,\n",
    " 'random_strength': 22.468752639603235,\n",
    " 'depth': 4,\n",
    " 'min_data_in_leaf': 31,\n",
    " 'leaf_estimation_iterations': 15\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.astype('int8')\n",
    "y_train = np.ravel(y_train).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0\n",
      "0:\tlearn: 0.6805051\ttest: 0.6805166\tbest: 0.6805166 (0)\ttotal: 202ms\tremaining: 9m 39s\n",
      "100:\tlearn: 0.5177409\ttest: 0.5182901\tbest: 0.5182901 (100)\ttotal: 18.6s\tremaining: 8m 29s\n",
      "200:\tlearn: 0.5053044\ttest: 0.5060821\tbest: 0.5060821 (200)\ttotal: 36.8s\tremaining: 8m 7s\n",
      "300:\tlearn: 0.4975663\ttest: 0.4986347\tbest: 0.4986347 (300)\ttotal: 55.5s\tremaining: 7m 53s\n",
      "400:\tlearn: 0.4880222\ttest: 0.4894856\tbest: 0.4894856 (400)\ttotal: 1m 14s\tremaining: 7m 35s\n",
      "500:\tlearn: 0.4819444\ttest: 0.4837040\tbest: 0.4837040 (500)\ttotal: 1m 32s\tremaining: 7m 15s\n",
      "600:\tlearn: 0.4782694\ttest: 0.4803071\tbest: 0.4803071 (600)\ttotal: 1m 49s\tremaining: 6m 54s\n",
      "700:\tlearn: 0.4757193\ttest: 0.4779912\tbest: 0.4779912 (700)\ttotal: 2m 7s\tremaining: 6m 34s\n",
      "800:\tlearn: 0.4737457\ttest: 0.4762922\tbest: 0.4762922 (800)\ttotal: 2m 25s\tremaining: 6m 14s\n",
      "900:\tlearn: 0.4721667\ttest: 0.4749949\tbest: 0.4749949 (900)\ttotal: 2m 43s\tremaining: 5m 56s\n",
      "1000:\tlearn: 0.4708459\ttest: 0.4739423\tbest: 0.4739423 (1000)\ttotal: 3m 1s\tremaining: 5m 37s\n",
      "1100:\tlearn: 0.4697380\ttest: 0.4731047\tbest: 0.4731047 (1100)\ttotal: 3m 18s\tremaining: 5m 18s\n",
      "1200:\tlearn: 0.4687538\ttest: 0.4724308\tbest: 0.4724308 (1200)\ttotal: 3m 36s\tremaining: 4m 59s\n",
      "1300:\tlearn: 0.4678944\ttest: 0.4718676\tbest: 0.4718676 (1300)\ttotal: 3m 53s\tremaining: 4m 41s\n",
      "1400:\tlearn: 0.4671313\ttest: 0.4714425\tbest: 0.4714425 (1400)\ttotal: 4m 11s\tremaining: 4m 23s\n",
      "1500:\tlearn: 0.4664381\ttest: 0.4710650\tbest: 0.4710650 (1500)\ttotal: 4m 29s\tremaining: 4m 4s\n",
      "1600:\tlearn: 0.4657876\ttest: 0.4707609\tbest: 0.4707609 (1600)\ttotal: 4m 46s\tremaining: 3m 46s\n",
      "1700:\tlearn: 0.4652001\ttest: 0.4705055\tbest: 0.4705042 (1697)\ttotal: 5m 2s\tremaining: 3m 27s\n",
      "1800:\tlearn: 0.4646275\ttest: 0.4702587\tbest: 0.4702581 (1799)\ttotal: 5m 19s\tremaining: 3m 9s\n",
      "1900:\tlearn: 0.4641019\ttest: 0.4700727\tbest: 0.4700727 (1900)\ttotal: 5m 37s\tremaining: 2m 51s\n",
      "2000:\tlearn: 0.4635943\ttest: 0.4699223\tbest: 0.4699223 (2000)\ttotal: 5m 54s\tremaining: 2m 33s\n",
      "2100:\tlearn: 0.4631108\ttest: 0.4697884\tbest: 0.4697884 (2100)\ttotal: 6m 11s\tremaining: 2m 15s\n",
      "2200:\tlearn: 0.4626346\ttest: 0.4696292\tbest: 0.4696280 (2199)\ttotal: 6m 28s\tremaining: 1m 57s\n",
      "2300:\tlearn: 0.4621841\ttest: 0.4695334\tbest: 0.4695330 (2299)\ttotal: 6m 45s\tremaining: 1m 39s\n",
      "2400:\tlearn: 0.4617373\ttest: 0.4694637\tbest: 0.4694624 (2396)\ttotal: 7m 1s\tremaining: 1m 21s\n",
      "2500:\tlearn: 0.4613065\ttest: 0.4693903\tbest: 0.4693903 (2500)\ttotal: 7m 18s\tremaining: 1m 4s\n",
      "2600:\tlearn: 0.4608679\ttest: 0.4692982\tbest: 0.4692982 (2600)\ttotal: 7m 35s\tremaining: 46.4s\n",
      "2700:\tlearn: 0.4604520\ttest: 0.4692610\tbest: 0.4692595 (2698)\ttotal: 7m 51s\tremaining: 28.8s\n",
      "2800:\tlearn: 0.4600501\ttest: 0.4692250\tbest: 0.4692250 (2800)\ttotal: 8m 7s\tremaining: 11.3s\n",
      "2865:\tlearn: 0.4597831\ttest: 0.4691996\tbest: 0.4691996 (2865)\ttotal: 8m 18s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4691996123\n",
      "bestIteration = 2865\n",
      "\n",
      "auc: 0.855288\n",
      "Fold:1\n",
      "0:\tlearn: 0.6805164\ttest: 0.6805153\tbest: 0.6805153 (0)\ttotal: 221ms\tremaining: 10m 32s\n",
      "100:\tlearn: 0.5173979\ttest: 0.5169653\tbest: 0.5169653 (100)\ttotal: 23.8s\tremaining: 10m 52s\n",
      "200:\tlearn: 0.5053429\ttest: 0.5048380\tbest: 0.5048380 (200)\ttotal: 46.1s\tremaining: 10m 10s\n",
      "300:\tlearn: 0.4977944\ttest: 0.4972211\tbest: 0.4972211 (300)\ttotal: 1m 8s\tremaining: 9m 46s\n",
      "400:\tlearn: 0.4884522\ttest: 0.4879065\tbest: 0.4879065 (400)\ttotal: 1m 31s\tremaining: 9m 21s\n",
      "500:\tlearn: 0.4822408\ttest: 0.4817747\tbest: 0.4817747 (500)\ttotal: 1m 54s\tremaining: 8m 59s\n",
      "600:\tlearn: 0.4785030\ttest: 0.4782846\tbest: 0.4782846 (600)\ttotal: 2m 15s\tremaining: 8m 32s\n",
      "700:\tlearn: 0.4759024\ttest: 0.4759544\tbest: 0.4759544 (700)\ttotal: 2m 37s\tremaining: 8m 7s\n",
      "800:\tlearn: 0.4739290\ttest: 0.4742245\tbest: 0.4742245 (800)\ttotal: 2m 59s\tremaining: 7m 42s\n",
      "900:\tlearn: 0.4723589\ttest: 0.4728972\tbest: 0.4728972 (900)\ttotal: 3m 20s\tremaining: 7m 18s\n",
      "1000:\tlearn: 0.4710327\ttest: 0.4718720\tbest: 0.4718720 (1000)\ttotal: 3m 42s\tremaining: 6m 54s\n",
      "1100:\tlearn: 0.4698895\ttest: 0.4710371\tbest: 0.4710371 (1100)\ttotal: 4m 3s\tremaining: 6m 31s\n",
      "1200:\tlearn: 0.4689412\ttest: 0.4703903\tbest: 0.4703903 (1200)\ttotal: 4m 24s\tremaining: 6m 7s\n",
      "1300:\tlearn: 0.4680657\ttest: 0.4698124\tbest: 0.4698124 (1300)\ttotal: 4m 46s\tremaining: 5m 44s\n",
      "1400:\tlearn: 0.4673044\ttest: 0.4693765\tbest: 0.4693765 (1400)\ttotal: 5m 7s\tremaining: 5m 21s\n",
      "1500:\tlearn: 0.4666100\ttest: 0.4689923\tbest: 0.4689923 (1500)\ttotal: 5m 28s\tremaining: 4m 58s\n",
      "1600:\tlearn: 0.4659469\ttest: 0.4686270\tbest: 0.4686270 (1600)\ttotal: 5m 49s\tremaining: 4m 36s\n",
      "1700:\tlearn: 0.4653593\ttest: 0.4683592\tbest: 0.4683592 (1700)\ttotal: 6m 10s\tremaining: 4m 13s\n",
      "1800:\tlearn: 0.4647918\ttest: 0.4681325\tbest: 0.4681325 (1800)\ttotal: 6m 31s\tremaining: 3m 51s\n",
      "1900:\tlearn: 0.4642722\ttest: 0.4679150\tbest: 0.4679150 (1900)\ttotal: 6m 51s\tremaining: 3m 28s\n",
      "2000:\tlearn: 0.4637609\ttest: 0.4677260\tbest: 0.4677260 (2000)\ttotal: 7m 11s\tremaining: 3m 6s\n",
      "2100:\tlearn: 0.4632746\ttest: 0.4675670\tbest: 0.4675670 (2100)\ttotal: 7m 31s\tremaining: 2m 44s\n",
      "2200:\tlearn: 0.4628160\ttest: 0.4674857\tbest: 0.4674852 (2199)\ttotal: 7m 51s\tremaining: 2m 22s\n",
      "2300:\tlearn: 0.4623653\ttest: 0.4673831\tbest: 0.4673825 (2294)\ttotal: 8m 11s\tremaining: 2m\n",
      "2400:\tlearn: 0.4619104\ttest: 0.4672949\tbest: 0.4672923 (2394)\ttotal: 8m 31s\tremaining: 1m 39s\n",
      "2500:\tlearn: 0.4614730\ttest: 0.4672069\tbest: 0.4672069 (2500)\ttotal: 8m 52s\tremaining: 1m 17s\n",
      "2600:\tlearn: 0.4610431\ttest: 0.4671346\tbest: 0.4671341 (2599)\ttotal: 9m 11s\tremaining: 56.2s\n",
      "2700:\tlearn: 0.4606089\ttest: 0.4670285\tbest: 0.4670285 (2700)\ttotal: 9m 31s\tremaining: 34.9s\n",
      "2800:\tlearn: 0.4602001\ttest: 0.4669870\tbest: 0.4669839 (2797)\ttotal: 9m 51s\tremaining: 13.7s\n",
      "2865:\tlearn: 0.4599433\ttest: 0.4669753\tbest: 0.4669676 (2858)\ttotal: 10m 4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4669676452\n",
      "bestIteration = 2858\n",
      "\n",
      "Shrink model to first 2859 iterations.\n",
      "auc: 0.857042\n",
      "Fold:2\n",
      "0:\tlearn: 0.6805164\ttest: 0.6805507\tbest: 0.6805507 (0)\ttotal: 219ms\tremaining: 10m 26s\n",
      "100:\tlearn: 0.5179713\ttest: 0.5188039\tbest: 0.5188039 (100)\ttotal: 21.6s\tremaining: 9m 50s\n",
      "200:\tlearn: 0.5050137\ttest: 0.5057954\tbest: 0.5057954 (200)\ttotal: 41.8s\tremaining: 9m 14s\n",
      "300:\tlearn: 0.4980263\ttest: 0.4988237\tbest: 0.4988237 (300)\ttotal: 1m 1s\tremaining: 8m 48s\n",
      "400:\tlearn: 0.4881601\ttest: 0.4890377\tbest: 0.4890377 (400)\ttotal: 1m 23s\tremaining: 8m 32s\n",
      "500:\tlearn: 0.4820721\ttest: 0.4831986\tbest: 0.4831986 (500)\ttotal: 1m 44s\tremaining: 8m 11s\n",
      "600:\tlearn: 0.4783945\ttest: 0.4797741\tbest: 0.4797741 (600)\ttotal: 2m 3s\tremaining: 7m 46s\n",
      "700:\tlearn: 0.4758359\ttest: 0.4774310\tbest: 0.4774310 (700)\ttotal: 2m 24s\tremaining: 7m 24s\n",
      "800:\tlearn: 0.4738456\ttest: 0.4756912\tbest: 0.4756912 (800)\ttotal: 2m 44s\tremaining: 7m 3s\n",
      "900:\tlearn: 0.4722686\ttest: 0.4743750\tbest: 0.4743750 (900)\ttotal: 3m 4s\tremaining: 6m 42s\n",
      "1000:\tlearn: 0.4709642\ttest: 0.4733450\tbest: 0.4733450 (1000)\ttotal: 3m 25s\tremaining: 6m 22s\n",
      "1100:\tlearn: 0.4698477\ttest: 0.4724965\tbest: 0.4724965 (1100)\ttotal: 3m 46s\tremaining: 6m 3s\n",
      "1200:\tlearn: 0.4688776\ttest: 0.4718339\tbest: 0.4718339 (1200)\ttotal: 4m 7s\tremaining: 5m 43s\n",
      "1300:\tlearn: 0.4680158\ttest: 0.4712888\tbest: 0.4712888 (1300)\ttotal: 4m 27s\tremaining: 5m 22s\n",
      "1400:\tlearn: 0.4672539\ttest: 0.4708283\tbest: 0.4708283 (1400)\ttotal: 4m 47s\tremaining: 5m 1s\n",
      "1500:\tlearn: 0.4665358\ttest: 0.4703869\tbest: 0.4703861 (1499)\ttotal: 5m 7s\tremaining: 4m 39s\n",
      "1600:\tlearn: 0.4658974\ttest: 0.4700618\tbest: 0.4700618 (1600)\ttotal: 5m 26s\tremaining: 4m 18s\n",
      "1700:\tlearn: 0.4652977\ttest: 0.4697837\tbest: 0.4697835 (1699)\ttotal: 5m 46s\tremaining: 3m 57s\n",
      "1800:\tlearn: 0.4647362\ttest: 0.4695391\tbest: 0.4695391 (1800)\ttotal: 6m 5s\tremaining: 3m 36s\n",
      "1900:\tlearn: 0.4642126\ttest: 0.4693455\tbest: 0.4693455 (1900)\ttotal: 6m 24s\tremaining: 3m 15s\n",
      "2000:\tlearn: 0.4637065\ttest: 0.4691742\tbest: 0.4691742 (2000)\ttotal: 6m 43s\tremaining: 2m 54s\n",
      "2100:\tlearn: 0.4632331\ttest: 0.4690653\tbest: 0.4690653 (2100)\ttotal: 7m 2s\tremaining: 2m 33s\n",
      "2200:\tlearn: 0.4627637\ttest: 0.4689609\tbest: 0.4689543 (2199)\ttotal: 7m 21s\tremaining: 2m 13s\n",
      "2300:\tlearn: 0.4623012\ttest: 0.4688471\tbest: 0.4688444 (2296)\ttotal: 7m 40s\tremaining: 1m 53s\n",
      "2400:\tlearn: 0.4618531\ttest: 0.4687201\tbest: 0.4687201 (2400)\ttotal: 7m 59s\tremaining: 1m 32s\n",
      "2500:\tlearn: 0.4614262\ttest: 0.4686539\tbest: 0.4686504 (2488)\ttotal: 8m 18s\tremaining: 1m 12s\n",
      "2600:\tlearn: 0.4610039\ttest: 0.4686056\tbest: 0.4686021 (2595)\ttotal: 8m 35s\tremaining: 52.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700:\tlearn: 0.4605805\ttest: 0.4685438\tbest: 0.4685408 (2693)\ttotal: 8m 52s\tremaining: 32.5s\n",
      "2800:\tlearn: 0.4601703\ttest: 0.4684801\tbest: 0.4684797 (2799)\ttotal: 9m 9s\tremaining: 12.7s\n",
      "2865:\tlearn: 0.4599048\ttest: 0.4684352\tbest: 0.4684340 (2863)\ttotal: 9m 20s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4684339504\n",
      "bestIteration = 2863\n",
      "\n",
      "Shrink model to first 2864 iterations.\n",
      "auc: 0.855955\n",
      "Fold:3\n",
      "0:\tlearn: 0.6805222\ttest: 0.6805164\tbest: 0.6805164 (0)\ttotal: 183ms\tremaining: 8m 44s\n",
      "100:\tlearn: 0.5162639\ttest: 0.5170566\tbest: 0.5170566 (100)\ttotal: 18.8s\tremaining: 8m 34s\n",
      "200:\tlearn: 0.5041355\ttest: 0.5047403\tbest: 0.5047403 (200)\ttotal: 36.9s\tremaining: 8m 9s\n",
      "300:\tlearn: 0.4969913\ttest: 0.4974878\tbest: 0.4974878 (300)\ttotal: 54.9s\tremaining: 7m 47s\n",
      "400:\tlearn: 0.4878230\ttest: 0.4882878\tbest: 0.4882878 (400)\ttotal: 1m 13s\tremaining: 7m 34s\n",
      "500:\tlearn: 0.4819572\ttest: 0.4824702\tbest: 0.4824702 (500)\ttotal: 1m 32s\tremaining: 7m 14s\n",
      "600:\tlearn: 0.4783415\ttest: 0.4789941\tbest: 0.4789941 (600)\ttotal: 1m 49s\tremaining: 6m 53s\n",
      "700:\tlearn: 0.4758317\ttest: 0.4766213\tbest: 0.4766213 (700)\ttotal: 2m 7s\tremaining: 6m 34s\n",
      "800:\tlearn: 0.4738817\ttest: 0.4748633\tbest: 0.4748633 (800)\ttotal: 2m 25s\tremaining: 6m 14s\n",
      "900:\tlearn: 0.4723043\ttest: 0.4735255\tbest: 0.4735255 (900)\ttotal: 2m 42s\tremaining: 5m 54s\n",
      "1000:\tlearn: 0.4710064\ttest: 0.4724936\tbest: 0.4724936 (1000)\ttotal: 3m\tremaining: 5m 35s\n",
      "1100:\tlearn: 0.4699111\ttest: 0.4716415\tbest: 0.4716415 (1100)\ttotal: 3m 17s\tremaining: 5m 16s\n",
      "1200:\tlearn: 0.4689542\ttest: 0.4709361\tbest: 0.4709361 (1200)\ttotal: 3m 34s\tremaining: 4m 57s\n",
      "1300:\tlearn: 0.4681157\ttest: 0.4703208\tbest: 0.4703208 (1300)\ttotal: 3m 51s\tremaining: 4m 39s\n",
      "1400:\tlearn: 0.4673764\ttest: 0.4698421\tbest: 0.4698421 (1400)\ttotal: 4m 9s\tremaining: 4m 20s\n",
      "1500:\tlearn: 0.4666941\ttest: 0.4694441\tbest: 0.4694441 (1500)\ttotal: 4m 26s\tremaining: 4m 2s\n",
      "1600:\tlearn: 0.4660400\ttest: 0.4690616\tbest: 0.4690616 (1600)\ttotal: 4m 43s\tremaining: 3m 43s\n",
      "1700:\tlearn: 0.4654599\ttest: 0.4687997\tbest: 0.4687997 (1700)\ttotal: 5m\tremaining: 3m 25s\n",
      "1800:\tlearn: 0.4648909\ttest: 0.4685373\tbest: 0.4685373 (1800)\ttotal: 5m 18s\tremaining: 3m 8s\n",
      "1900:\tlearn: 0.4643574\ttest: 0.4683350\tbest: 0.4683323 (1895)\ttotal: 5m 35s\tremaining: 2m 50s\n",
      "2000:\tlearn: 0.4638546\ttest: 0.4681546\tbest: 0.4681546 (2000)\ttotal: 5m 51s\tremaining: 2m 32s\n",
      "2100:\tlearn: 0.4633607\ttest: 0.4680008\tbest: 0.4680008 (2100)\ttotal: 6m 8s\tremaining: 2m 14s\n",
      "2200:\tlearn: 0.4628867\ttest: 0.4678562\tbest: 0.4678547 (2199)\ttotal: 6m 24s\tremaining: 1m 56s\n",
      "2300:\tlearn: 0.4624313\ttest: 0.4677364\tbest: 0.4677364 (2300)\ttotal: 6m 41s\tremaining: 1m 38s\n",
      "2400:\tlearn: 0.4619857\ttest: 0.4676207\tbest: 0.4676207 (2400)\ttotal: 6m 57s\tremaining: 1m 20s\n",
      "2500:\tlearn: 0.4615468\ttest: 0.4675196\tbest: 0.4675196 (2500)\ttotal: 7m 14s\tremaining: 1m 3s\n",
      "2600:\tlearn: 0.4611229\ttest: 0.4674540\tbest: 0.4674540 (2600)\ttotal: 7m 31s\tremaining: 46s\n",
      "2700:\tlearn: 0.4607085\ttest: 0.4674099\tbest: 0.4674024 (2673)\ttotal: 7m 47s\tremaining: 28.6s\n",
      "2800:\tlearn: 0.4602992\ttest: 0.4673516\tbest: 0.4673514 (2799)\ttotal: 8m 4s\tremaining: 11.2s\n",
      "2865:\tlearn: 0.4600361\ttest: 0.4673033\tbest: 0.4673033 (2865)\ttotal: 8m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4673033156\n",
      "bestIteration = 2865\n",
      "\n",
      "auc: 0.856610\n",
      "Fold:4\n",
      "0:\tlearn: 0.6805066\ttest: 0.6805016\tbest: 0.6805016 (0)\ttotal: 185ms\tremaining: 8m 50s\n",
      "100:\tlearn: 0.5173145\ttest: 0.5177195\tbest: 0.5177195 (100)\ttotal: 18.8s\tremaining: 8m 34s\n",
      "200:\tlearn: 0.5050128\ttest: 0.5055564\tbest: 0.5055564 (200)\ttotal: 36.9s\tremaining: 8m 9s\n",
      "300:\tlearn: 0.4977793\ttest: 0.4984207\tbest: 0.4984207 (300)\ttotal: 54.9s\tremaining: 7m 47s\n",
      "400:\tlearn: 0.4881123\ttest: 0.4888766\tbest: 0.4888766 (400)\ttotal: 1m 13s\tremaining: 7m 31s\n",
      "500:\tlearn: 0.4820087\ttest: 0.4830375\tbest: 0.4830375 (500)\ttotal: 1m 31s\tremaining: 7m 10s\n",
      "600:\tlearn: 0.4782848\ttest: 0.4795617\tbest: 0.4795617 (600)\ttotal: 1m 49s\tremaining: 6m 52s\n",
      "700:\tlearn: 0.4756800\ttest: 0.4771689\tbest: 0.4771689 (700)\ttotal: 2m 6s\tremaining: 6m 31s\n",
      "800:\tlearn: 0.4737265\ttest: 0.4754831\tbest: 0.4754831 (800)\ttotal: 2m 24s\tremaining: 6m 11s\n",
      "900:\tlearn: 0.4721392\ttest: 0.4741406\tbest: 0.4741406 (900)\ttotal: 2m 41s\tremaining: 5m 52s\n",
      "1000:\tlearn: 0.4708467\ttest: 0.4731063\tbest: 0.4731063 (1000)\ttotal: 2m 58s\tremaining: 5m 33s\n",
      "1100:\tlearn: 0.4697493\ttest: 0.4723060\tbest: 0.4723060 (1100)\ttotal: 3m 16s\tremaining: 5m 14s\n",
      "1200:\tlearn: 0.4688027\ttest: 0.4716414\tbest: 0.4716414 (1200)\ttotal: 3m 33s\tremaining: 4m 55s\n",
      "1300:\tlearn: 0.4679374\ttest: 0.4710343\tbest: 0.4710343 (1300)\ttotal: 3m 50s\tremaining: 4m 37s\n",
      "1400:\tlearn: 0.4671892\ttest: 0.4706068\tbest: 0.4706068 (1400)\ttotal: 4m 7s\tremaining: 4m 18s\n",
      "1500:\tlearn: 0.4664871\ttest: 0.4701908\tbest: 0.4701908 (1500)\ttotal: 4m 24s\tremaining: 4m\n",
      "1600:\tlearn: 0.4658372\ttest: 0.4698581\tbest: 0.4698581 (1600)\ttotal: 4m 41s\tremaining: 3m 42s\n",
      "1700:\tlearn: 0.4652485\ttest: 0.4695815\tbest: 0.4695815 (1700)\ttotal: 4m 57s\tremaining: 3m 24s\n",
      "1800:\tlearn: 0.4646858\ttest: 0.4693306\tbest: 0.4693306 (1800)\ttotal: 5m 14s\tremaining: 3m 6s\n",
      "1900:\tlearn: 0.4641610\ttest: 0.4691406\tbest: 0.4691406 (1900)\ttotal: 5m 31s\tremaining: 2m 48s\n",
      "2000:\tlearn: 0.4636371\ttest: 0.4689321\tbest: 0.4689321 (2000)\ttotal: 5m 48s\tremaining: 2m 30s\n",
      "2100:\tlearn: 0.4631606\ttest: 0.4687881\tbest: 0.4687879 (2099)\ttotal: 6m 5s\tremaining: 2m 13s\n",
      "2200:\tlearn: 0.4627036\ttest: 0.4686642\tbest: 0.4686642 (2200)\ttotal: 6m 21s\tremaining: 1m 55s\n",
      "2300:\tlearn: 0.4622464\ttest: 0.4685502\tbest: 0.4685475 (2299)\ttotal: 6m 38s\tremaining: 1m 37s\n",
      "2400:\tlearn: 0.4617826\ttest: 0.4684702\tbest: 0.4684679 (2399)\ttotal: 6m 55s\tremaining: 1m 20s\n",
      "2500:\tlearn: 0.4613570\ttest: 0.4684239\tbest: 0.4684207 (2494)\ttotal: 7m 11s\tremaining: 1m 3s\n",
      "2600:\tlearn: 0.4609321\ttest: 0.4683619\tbest: 0.4683613 (2567)\ttotal: 7m 27s\tremaining: 45.6s\n",
      "2700:\tlearn: 0.4605096\ttest: 0.4683007\tbest: 0.4682979 (2696)\ttotal: 7m 43s\tremaining: 28.3s\n",
      "2800:\tlearn: 0.4600854\ttest: 0.4682386\tbest: 0.4682374 (2798)\ttotal: 7m 59s\tremaining: 11.1s\n",
      "2865:\tlearn: 0.4598234\ttest: 0.4682005\tbest: 0.4681926 (2852)\ttotal: 8m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4681925658\n",
      "bestIteration = 2852\n",
      "\n",
      "Shrink model to first 2853 iterations.\n",
      "auc: 0.855976\n",
      "Fold:5\n",
      "0:\tlearn: 0.6804874\ttest: 0.6805442\tbest: 0.6805442 (0)\ttotal: 180ms\tremaining: 8m 35s\n",
      "100:\tlearn: 0.5174198\ttest: 0.5187403\tbest: 0.5187403 (100)\ttotal: 18.9s\tremaining: 8m 38s\n",
      "200:\tlearn: 0.5042251\ttest: 0.5057591\tbest: 0.5057591 (200)\ttotal: 37.6s\tremaining: 8m 18s\n",
      "300:\tlearn: 0.4970495\ttest: 0.4987143\tbest: 0.4987143 (300)\ttotal: 55.2s\tremaining: 7m 50s\n",
      "400:\tlearn: 0.4879120\ttest: 0.4898872\tbest: 0.4898872 (400)\ttotal: 1m 13s\tremaining: 7m 32s\n",
      "500:\tlearn: 0.4819600\ttest: 0.4841802\tbest: 0.4841802 (500)\ttotal: 1m 31s\tremaining: 7m 12s\n",
      "600:\tlearn: 0.4782789\ttest: 0.4807483\tbest: 0.4807483 (600)\ttotal: 1m 49s\tremaining: 6m 51s\n",
      "700:\tlearn: 0.4756941\ttest: 0.4784254\tbest: 0.4784254 (700)\ttotal: 2m 6s\tremaining: 6m 30s\n",
      "800:\tlearn: 0.4737193\ttest: 0.4766770\tbest: 0.4766770 (800)\ttotal: 2m 23s\tremaining: 6m 10s\n",
      "900:\tlearn: 0.4721275\ttest: 0.4753530\tbest: 0.4753530 (900)\ttotal: 2m 41s\tremaining: 5m 52s\n",
      "1000:\tlearn: 0.4708192\ttest: 0.4743115\tbest: 0.4743115 (1000)\ttotal: 2m 59s\tremaining: 5m 33s\n",
      "1100:\tlearn: 0.4697009\ttest: 0.4734520\tbest: 0.4734520 (1100)\ttotal: 3m 16s\tremaining: 5m 15s\n",
      "1200:\tlearn: 0.4687426\ttest: 0.4727860\tbest: 0.4727860 (1200)\ttotal: 3m 33s\tremaining: 4m 56s\n",
      "1300:\tlearn: 0.4678745\ttest: 0.4721931\tbest: 0.4721931 (1300)\ttotal: 3m 51s\tremaining: 4m 38s\n",
      "1400:\tlearn: 0.4671037\ttest: 0.4717391\tbest: 0.4717391 (1400)\ttotal: 4m 8s\tremaining: 4m 19s\n",
      "1500:\tlearn: 0.4664060\ttest: 0.4713126\tbest: 0.4713126 (1500)\ttotal: 4m 25s\tremaining: 4m 1s\n",
      "1600:\tlearn: 0.4657471\ttest: 0.4709673\tbest: 0.4709673 (1600)\ttotal: 4m 42s\tremaining: 3m 43s\n",
      "1700:\tlearn: 0.4651632\ttest: 0.4707334\tbest: 0.4707304 (1698)\ttotal: 4m 59s\tremaining: 3m 25s\n",
      "1800:\tlearn: 0.4645967\ttest: 0.4704877\tbest: 0.4704877 (1800)\ttotal: 5m 16s\tremaining: 3m 6s\n",
      "1900:\tlearn: 0.4640595\ttest: 0.4702665\tbest: 0.4702657 (1897)\ttotal: 5m 32s\tremaining: 2m 48s\n",
      "2000:\tlearn: 0.4635652\ttest: 0.4700866\tbest: 0.4700866 (2000)\ttotal: 5m 50s\tremaining: 2m 31s\n",
      "2100:\tlearn: 0.4630758\ttest: 0.4699671\tbest: 0.4699671 (2100)\ttotal: 6m 7s\tremaining: 2m 13s\n",
      "2200:\tlearn: 0.4626127\ttest: 0.4698440\tbest: 0.4698432 (2199)\ttotal: 6m 24s\tremaining: 1m 56s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300:\tlearn: 0.4621585\ttest: 0.4697697\tbest: 0.4697658 (2293)\ttotal: 6m 41s\tremaining: 1m 38s\n",
      "2400:\tlearn: 0.4617278\ttest: 0.4696950\tbest: 0.4696950 (2400)\ttotal: 6m 59s\tremaining: 1m 21s\n",
      "2500:\tlearn: 0.4612831\ttest: 0.4695934\tbest: 0.4695923 (2498)\ttotal: 7m 19s\tremaining: 1m 4s\n",
      "2600:\tlearn: 0.4608321\ttest: 0.4694870\tbest: 0.4694870 (2600)\ttotal: 7m 39s\tremaining: 46.8s\n",
      "2700:\tlearn: 0.4604116\ttest: 0.4694201\tbest: 0.4694201 (2700)\ttotal: 7m 58s\tremaining: 29.3s\n",
      "2800:\tlearn: 0.4599989\ttest: 0.4693687\tbest: 0.4693687 (2800)\ttotal: 8m 23s\tremaining: 11.7s\n",
      "2865:\tlearn: 0.4597355\ttest: 0.4693351\tbest: 0.4693351 (2865)\ttotal: 8m 37s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4693351349\n",
      "bestIteration = 2865\n",
      "\n",
      "auc: 0.855331\n",
      "Fold:6\n",
      "0:\tlearn: 0.6805521\ttest: 0.6804797\tbest: 0.6804797 (0)\ttotal: 209ms\tremaining: 9m 58s\n",
      "100:\tlearn: 0.5176329\ttest: 0.5161793\tbest: 0.5161793 (100)\ttotal: 20.7s\tremaining: 9m 27s\n",
      "200:\tlearn: 0.5052333\ttest: 0.5037435\tbest: 0.5037435 (200)\ttotal: 40.4s\tremaining: 8m 55s\n",
      "300:\tlearn: 0.4978104\ttest: 0.4965824\tbest: 0.4965824 (300)\ttotal: 1m\tremaining: 8m 32s\n",
      "400:\tlearn: 0.4884751\ttest: 0.4875229\tbest: 0.4875229 (400)\ttotal: 1m 22s\tremaining: 8m 28s\n",
      "500:\tlearn: 0.4823577\ttest: 0.4817482\tbest: 0.4817482 (500)\ttotal: 1m 41s\tremaining: 7m 59s\n",
      "600:\tlearn: 0.4786225\ttest: 0.4782763\tbest: 0.4782763 (600)\ttotal: 2m\tremaining: 7m 35s\n",
      "700:\tlearn: 0.4759772\ttest: 0.4759068\tbest: 0.4759068 (700)\ttotal: 2m 19s\tremaining: 7m 12s\n",
      "800:\tlearn: 0.4739638\ttest: 0.4741401\tbest: 0.4741401 (800)\ttotal: 2m 38s\tremaining: 6m 49s\n",
      "900:\tlearn: 0.4723667\ttest: 0.4728921\tbest: 0.4728921 (900)\ttotal: 2m 57s\tremaining: 6m 27s\n",
      "1000:\tlearn: 0.4710677\ttest: 0.4719122\tbest: 0.4719122 (1000)\ttotal: 3m 21s\tremaining: 6m 14s\n",
      "1100:\tlearn: 0.4699595\ttest: 0.4710756\tbest: 0.4710756 (1100)\ttotal: 3m 42s\tremaining: 5m 56s\n",
      "1200:\tlearn: 0.4689816\ttest: 0.4704103\tbest: 0.4704103 (1200)\ttotal: 4m 3s\tremaining: 5m 37s\n",
      "1300:\tlearn: 0.4681314\ttest: 0.4698918\tbest: 0.4698918 (1300)\ttotal: 4m 24s\tremaining: 5m 18s\n",
      "1400:\tlearn: 0.4673611\ttest: 0.4694261\tbest: 0.4694261 (1400)\ttotal: 4m 54s\tremaining: 5m 7s\n",
      "1500:\tlearn: 0.4666448\ttest: 0.4690214\tbest: 0.4690214 (1500)\ttotal: 5m 22s\tremaining: 4m 53s\n",
      "1600:\tlearn: 0.4659902\ttest: 0.4686852\tbest: 0.4686852 (1600)\ttotal: 5m 44s\tremaining: 4m 32s\n",
      "1700:\tlearn: 0.4653899\ttest: 0.4684446\tbest: 0.4684446 (1700)\ttotal: 6m 8s\tremaining: 4m 12s\n",
      "1800:\tlearn: 0.4648248\ttest: 0.4682152\tbest: 0.4682152 (1800)\ttotal: 6m 27s\tremaining: 3m 49s\n",
      "1900:\tlearn: 0.4643045\ttest: 0.4680871\tbest: 0.4680871 (1900)\ttotal: 6m 46s\tremaining: 3m 26s\n",
      "2000:\tlearn: 0.4637950\ttest: 0.4678813\tbest: 0.4678813 (2000)\ttotal: 7m 4s\tremaining: 3m 3s\n",
      "2100:\tlearn: 0.4633164\ttest: 0.4677637\tbest: 0.4677637 (2100)\ttotal: 7m 23s\tremaining: 2m 41s\n",
      "2200:\tlearn: 0.4628350\ttest: 0.4676442\tbest: 0.4676411 (2194)\ttotal: 7m 41s\tremaining: 2m 19s\n",
      "2300:\tlearn: 0.4623745\ttest: 0.4675334\tbest: 0.4675334 (2300)\ttotal: 7m 59s\tremaining: 1m 57s\n",
      "2400:\tlearn: 0.4619274\ttest: 0.4674795\tbest: 0.4674750 (2371)\ttotal: 8m 16s\tremaining: 1m 36s\n",
      "2500:\tlearn: 0.4614873\ttest: 0.4674044\tbest: 0.4674042 (2498)\ttotal: 8m 33s\tremaining: 1m 15s\n",
      "2600:\tlearn: 0.4610600\ttest: 0.4673305\tbest: 0.4673299 (2598)\ttotal: 8m 50s\tremaining: 54.1s\n",
      "2700:\tlearn: 0.4606568\ttest: 0.4673263\tbest: 0.4673231 (2690)\ttotal: 9m 7s\tremaining: 33.4s\n",
      "2800:\tlearn: 0.4602419\ttest: 0.4672900\tbest: 0.4672899 (2788)\ttotal: 9m 24s\tremaining: 13.1s\n",
      "2865:\tlearn: 0.4599815\ttest: 0.4672600\tbest: 0.4672565 (2859)\ttotal: 9m 36s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4672565019\n",
      "bestIteration = 2859\n",
      "\n",
      "Shrink model to first 2860 iterations.\n",
      "auc: 0.856662\n",
      "Fold:7\n",
      "0:\tlearn: 0.6805404\ttest: 0.6805303\tbest: 0.6805303 (0)\ttotal: 501ms\tremaining: 23m 53s\n",
      "100:\tlearn: 0.5172028\ttest: 0.5182035\tbest: 0.5182035 (100)\ttotal: 23s\tremaining: 10m 29s\n",
      "200:\tlearn: 0.5044126\ttest: 0.5055067\tbest: 0.5055067 (200)\ttotal: 43.6s\tremaining: 9m 38s\n",
      "300:\tlearn: 0.4974257\ttest: 0.4985972\tbest: 0.4985972 (300)\ttotal: 1m 3s\tremaining: 8m 59s\n",
      "400:\tlearn: 0.4881828\ttest: 0.4893826\tbest: 0.4893826 (400)\ttotal: 1m 23s\tremaining: 8m 33s\n",
      "500:\tlearn: 0.4822060\ttest: 0.4835635\tbest: 0.4835635 (500)\ttotal: 1m 44s\tremaining: 8m 11s\n",
      "600:\tlearn: 0.4784645\ttest: 0.4800053\tbest: 0.4800053 (600)\ttotal: 2m 4s\tremaining: 7m 50s\n",
      "700:\tlearn: 0.4758469\ttest: 0.4776678\tbest: 0.4776678 (700)\ttotal: 2m 24s\tremaining: 7m 27s\n",
      "800:\tlearn: 0.4738443\ttest: 0.4759011\tbest: 0.4759011 (800)\ttotal: 2m 44s\tremaining: 7m 3s\n",
      "900:\tlearn: 0.4722502\ttest: 0.4745401\tbest: 0.4745401 (900)\ttotal: 3m 3s\tremaining: 6m 39s\n",
      "1000:\tlearn: 0.4709476\ttest: 0.4735108\tbest: 0.4735108 (1000)\ttotal: 3m 24s\tremaining: 6m 21s\n",
      "1100:\tlearn: 0.4698175\ttest: 0.4726714\tbest: 0.4726714 (1100)\ttotal: 4m 1s\tremaining: 6m 26s\n",
      "1200:\tlearn: 0.4688556\ttest: 0.4720303\tbest: 0.4720303 (1200)\ttotal: 4m 22s\tremaining: 6m 3s\n",
      "1300:\tlearn: 0.4679877\ttest: 0.4714335\tbest: 0.4714335 (1300)\ttotal: 4m 46s\tremaining: 5m 44s\n",
      "1400:\tlearn: 0.4672091\ttest: 0.4709790\tbest: 0.4709790 (1400)\ttotal: 5m 10s\tremaining: 5m 25s\n",
      "1500:\tlearn: 0.4665261\ttest: 0.4706031\tbest: 0.4706031 (1500)\ttotal: 5m 32s\tremaining: 5m 2s\n",
      "1600:\tlearn: 0.4658889\ttest: 0.4703038\tbest: 0.4703038 (1600)\ttotal: 5m 57s\tremaining: 4m 42s\n",
      "1700:\tlearn: 0.4652996\ttest: 0.4700364\tbest: 0.4700364 (1700)\ttotal: 6m 36s\tremaining: 4m 31s\n",
      "1800:\tlearn: 0.4647403\ttest: 0.4698045\tbest: 0.4698040 (1799)\ttotal: 7m 4s\tremaining: 4m 11s\n",
      "1900:\tlearn: 0.4642009\ttest: 0.4695739\tbest: 0.4695727 (1899)\ttotal: 7m 24s\tremaining: 3m 45s\n",
      "2000:\tlearn: 0.4636938\ttest: 0.4694174\tbest: 0.4694174 (2000)\ttotal: 7m 44s\tremaining: 3m 20s\n",
      "2100:\tlearn: 0.4632083\ttest: 0.4692737\tbest: 0.4692704 (2098)\ttotal: 8m 18s\tremaining: 3m 1s\n",
      "2200:\tlearn: 0.4627555\ttest: 0.4691733\tbest: 0.4691706 (2199)\ttotal: 9m 3s\tremaining: 2m 44s\n",
      "2300:\tlearn: 0.4622986\ttest: 0.4690748\tbest: 0.4690748 (2300)\ttotal: 9m 53s\tremaining: 2m 25s\n",
      "2400:\tlearn: 0.4618619\ttest: 0.4689967\tbest: 0.4689967 (2400)\ttotal: 10m 43s\tremaining: 2m 4s\n",
      "2500:\tlearn: 0.4613994\ttest: 0.4688634\tbest: 0.4688634 (2500)\ttotal: 11m 30s\tremaining: 1m 40s\n",
      "2600:\tlearn: 0.4609788\ttest: 0.4687849\tbest: 0.4687801 (2593)\ttotal: 11m 53s\tremaining: 1m 12s\n",
      "2700:\tlearn: 0.4605503\ttest: 0.4687029\tbest: 0.4687029 (2700)\ttotal: 12m 16s\tremaining: 45s\n",
      "2800:\tlearn: 0.4601461\ttest: 0.4686666\tbest: 0.4686620 (2798)\ttotal: 12m 48s\tremaining: 17.8s\n",
      "2865:\tlearn: 0.4598796\ttest: 0.4686262\tbest: 0.4686244 (2864)\ttotal: 13m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4686244078\n",
      "bestIteration = 2864\n",
      "\n",
      "Shrink model to first 2865 iterations.\n",
      "auc: 0.855752\n",
      "Fold:8\n",
      "0:\tlearn: 0.6805359\ttest: 0.6804249\tbest: 0.6804249 (0)\ttotal: 474ms\tremaining: 22m 37s\n",
      "100:\tlearn: 0.5173495\ttest: 0.5152808\tbest: 0.5152808 (100)\ttotal: 26.3s\tremaining: 12m\n",
      "200:\tlearn: 0.5046664\ttest: 0.5026557\tbest: 0.5026557 (200)\ttotal: 1m 5s\tremaining: 14m 25s\n",
      "300:\tlearn: 0.4973909\ttest: 0.4953186\tbest: 0.4953186 (300)\ttotal: 1m 55s\tremaining: 16m 25s\n",
      "400:\tlearn: 0.4880386\ttest: 0.4858824\tbest: 0.4858824 (400)\ttotal: 2m 22s\tremaining: 14m 38s\n",
      "500:\tlearn: 0.4822746\ttest: 0.4799736\tbest: 0.4799736 (500)\ttotal: 2m 46s\tremaining: 13m 7s\n",
      "600:\tlearn: 0.4786874\ttest: 0.4764887\tbest: 0.4764887 (600)\ttotal: 3m 9s\tremaining: 11m 54s\n",
      "700:\tlearn: 0.4761214\ttest: 0.4742144\tbest: 0.4742144 (700)\ttotal: 3m 30s\tremaining: 10m 49s\n",
      "800:\tlearn: 0.4741659\ttest: 0.4725226\tbest: 0.4725226 (800)\ttotal: 3m 50s\tremaining: 9m 53s\n",
      "900:\tlearn: 0.4725901\ttest: 0.4712850\tbest: 0.4712850 (900)\ttotal: 4m 11s\tremaining: 9m 9s\n",
      "1000:\tlearn: 0.4712826\ttest: 0.4702651\tbest: 0.4702651 (1000)\ttotal: 4m 32s\tremaining: 8m 27s\n",
      "1100:\tlearn: 0.4701845\ttest: 0.4694436\tbest: 0.4694436 (1100)\ttotal: 4m 52s\tremaining: 7m 49s\n",
      "1200:\tlearn: 0.4692199\ttest: 0.4687529\tbest: 0.4687529 (1200)\ttotal: 5m 16s\tremaining: 7m 19s\n",
      "1300:\tlearn: 0.4683708\ttest: 0.4682228\tbest: 0.4682228 (1300)\ttotal: 5m 37s\tremaining: 6m 46s\n",
      "1400:\tlearn: 0.4676043\ttest: 0.4677379\tbest: 0.4677379 (1400)\ttotal: 5m 57s\tremaining: 6m 13s\n",
      "1500:\tlearn: 0.4669181\ttest: 0.4673551\tbest: 0.4673551 (1500)\ttotal: 6m 17s\tremaining: 5m 43s\n",
      "1600:\tlearn: 0.4662965\ttest: 0.4670540\tbest: 0.4670540 (1600)\ttotal: 6m 38s\tremaining: 5m 14s\n",
      "1700:\tlearn: 0.4656866\ttest: 0.4667236\tbest: 0.4667236 (1700)\ttotal: 7m\tremaining: 4m 48s\n",
      "1800:\tlearn: 0.4651234\ttest: 0.4664987\tbest: 0.4664985 (1798)\ttotal: 7m 23s\tremaining: 4m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900:\tlearn: 0.4645999\ttest: 0.4663094\tbest: 0.4663094 (1900)\ttotal: 7m 42s\tremaining: 3m 54s\n",
      "2000:\tlearn: 0.4641007\ttest: 0.4661679\tbest: 0.4661634 (1997)\ttotal: 8m 1s\tremaining: 3m 28s\n",
      "2100:\tlearn: 0.4636130\ttest: 0.4660216\tbest: 0.4660216 (2100)\ttotal: 8m 18s\tremaining: 3m 1s\n",
      "2200:\tlearn: 0.4631368\ttest: 0.4658816\tbest: 0.4658816 (2200)\ttotal: 8m 35s\tremaining: 2m 35s\n",
      "2300:\tlearn: 0.4626859\ttest: 0.4658034\tbest: 0.4657974 (2298)\ttotal: 8m 51s\tremaining: 2m 10s\n",
      "2400:\tlearn: 0.4622284\ttest: 0.4656907\tbest: 0.4656902 (2398)\ttotal: 9m 9s\tremaining: 1m 46s\n",
      "2500:\tlearn: 0.4617861\ttest: 0.4656013\tbest: 0.4656007 (2499)\ttotal: 9m 26s\tremaining: 1m 22s\n",
      "2600:\tlearn: 0.4613557\ttest: 0.4655422\tbest: 0.4655394 (2570)\ttotal: 9m 44s\tremaining: 59.5s\n",
      "2700:\tlearn: 0.4609392\ttest: 0.4654731\tbest: 0.4654731 (2700)\ttotal: 10m 1s\tremaining: 36.7s\n",
      "2800:\tlearn: 0.4605192\ttest: 0.4653975\tbest: 0.4653975 (2800)\ttotal: 10m 17s\tremaining: 14.3s\n",
      "2865:\tlearn: 0.4602604\ttest: 0.4653684\tbest: 0.4653673 (2862)\ttotal: 10m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.465367335\n",
      "bestIteration = 2862\n",
      "\n",
      "Shrink model to first 2863 iterations.\n",
      "auc: 0.858181\n",
      "Fold:9\n",
      "0:\tlearn: 0.6805354\ttest: 0.6804900\tbest: 0.6804900 (0)\ttotal: 190ms\tremaining: 9m 5s\n",
      "100:\tlearn: 0.5164521\ttest: 0.5165308\tbest: 0.5165308 (100)\ttotal: 20.3s\tremaining: 9m 14s\n",
      "200:\tlearn: 0.5042283\ttest: 0.5047074\tbest: 0.5047074 (200)\ttotal: 40.7s\tremaining: 8m 59s\n",
      "300:\tlearn: 0.4975417\ttest: 0.4983845\tbest: 0.4983845 (300)\ttotal: 1m\tremaining: 8m 36s\n",
      "400:\tlearn: 0.4879237\ttest: 0.4889417\tbest: 0.4889417 (400)\ttotal: 1m 22s\tremaining: 8m 25s\n",
      "500:\tlearn: 0.4819652\ttest: 0.4833042\tbest: 0.4833042 (500)\ttotal: 1m 44s\tremaining: 8m 13s\n",
      "600:\tlearn: 0.4783017\ttest: 0.4800037\tbest: 0.4800037 (600)\ttotal: 2m 6s\tremaining: 7m 57s\n",
      "700:\tlearn: 0.4757475\ttest: 0.4778389\tbest: 0.4778389 (700)\ttotal: 2m 28s\tremaining: 7m 37s\n",
      "800:\tlearn: 0.4737424\ttest: 0.4761854\tbest: 0.4761854 (800)\ttotal: 2m 50s\tremaining: 7m 20s\n",
      "900:\tlearn: 0.4721410\ttest: 0.4749301\tbest: 0.4749301 (900)\ttotal: 3m 12s\tremaining: 6m 58s\n",
      "1000:\tlearn: 0.4708255\ttest: 0.4739447\tbest: 0.4739447 (1000)\ttotal: 3m 32s\tremaining: 6m 35s\n",
      "1100:\tlearn: 0.4697118\ttest: 0.4731704\tbest: 0.4731704 (1100)\ttotal: 3m 50s\tremaining: 6m 9s\n",
      "1200:\tlearn: 0.4687580\ttest: 0.4725722\tbest: 0.4725722 (1200)\ttotal: 4m 8s\tremaining: 5m 45s\n",
      "1300:\tlearn: 0.4678775\ttest: 0.4720173\tbest: 0.4720173 (1300)\ttotal: 4m 26s\tremaining: 5m 20s\n",
      "1400:\tlearn: 0.4671314\ttest: 0.4716080\tbest: 0.4716080 (1400)\ttotal: 4m 44s\tremaining: 4m 57s\n",
      "1500:\tlearn: 0.4664302\ttest: 0.4712192\tbest: 0.4712192 (1500)\ttotal: 5m 4s\tremaining: 4m 36s\n",
      "1600:\tlearn: 0.4658041\ttest: 0.4709296\tbest: 0.4709296 (1600)\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "1700:\tlearn: 0.4652058\ttest: 0.4706535\tbest: 0.4706535 (1700)\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "1800:\tlearn: 0.4646588\ttest: 0.4704254\tbest: 0.4704254 (1800)\ttotal: 5m 59s\tremaining: 3m 32s\n",
      "1900:\tlearn: 0.4641103\ttest: 0.4702091\tbest: 0.4702091 (1900)\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "2000:\tlearn: 0.4636029\ttest: 0.4700400\tbest: 0.4700400 (2000)\ttotal: 6m 37s\tremaining: 2m 51s\n",
      "2100:\tlearn: 0.4631144\ttest: 0.4699116\tbest: 0.4699116 (2100)\ttotal: 6m 56s\tremaining: 2m 31s\n",
      "2200:\tlearn: 0.4626335\ttest: 0.4697708\tbest: 0.4697708 (2200)\ttotal: 7m 14s\tremaining: 2m 11s\n",
      "2300:\tlearn: 0.4621738\ttest: 0.4696857\tbest: 0.4696835 (2293)\ttotal: 7m 34s\tremaining: 1m 51s\n",
      "2400:\tlearn: 0.4617374\ttest: 0.4696209\tbest: 0.4696209 (2400)\ttotal: 7m 51s\tremaining: 1m 31s\n",
      "2500:\tlearn: 0.4613021\ttest: 0.4695170\tbest: 0.4695148 (2493)\ttotal: 8m 9s\tremaining: 1m 11s\n",
      "2600:\tlearn: 0.4608818\ttest: 0.4694767\tbest: 0.4694766 (2599)\ttotal: 8m 26s\tremaining: 51.6s\n",
      "2700:\tlearn: 0.4604591\ttest: 0.4694211\tbest: 0.4694211 (2700)\ttotal: 8m 42s\tremaining: 31.9s\n",
      "2800:\tlearn: 0.4600335\ttest: 0.4693631\tbest: 0.4693616 (2798)\ttotal: 8m 59s\tremaining: 12.5s\n",
      "2865:\tlearn: 0.4597655\ttest: 0.4693187\tbest: 0.4693163 (2856)\ttotal: 9m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4693163266\n",
      "bestIteration = 2856\n",
      "\n",
      "Shrink model to first 2857 iterations.\n",
      "auc: 0.855128\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10,random_state=2020,shuffle=True)\n",
    "cat_test_pred = np.zeros(len(test))\n",
    "cat_train_meta_pred = np.zeros(len(y_train_meta))\n",
    "\n",
    "for fold,(train_idx, val_idx) in enumerate(folds.split(X=X_train,y=y_train)):\n",
    "    print(f'Fold:{fold}')\n",
    "    #create pool objects\n",
    "    train = Pool(data= X_train.iloc[train_idx,:], label=y_train[train_idx])\n",
    "    val = Pool(data= X_train.iloc[val_idx,:], label=y_train[val_idx])\n",
    "    \n",
    "    #create cat model object and train\n",
    "    model_cat = CatBoostClassifier(**cat_params)\n",
    "    model_cat.fit(X=train,\n",
    "        eval_set=val,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=100,\n",
    "    )\n",
    "\n",
    "    #predictions for train_meta and bagging\n",
    "    train_meta_pred_fold = model_cat.predict(X_train_meta)\n",
    "    cat_train_meta_pred = np.column_stack((cat_train_meta_pred,train_meta_pred_fold))\n",
    "    \n",
    "    #prediction for test and bagging\n",
    "    test_pred_fold = model_cat.predict(X_test)\n",
    "    cat_test_pred = np.column_stack((cat_test_pred,test_pred_fold))\n",
    "    \n",
    "    #roc_auc_score using training CV for personal satisfaction XD\n",
    "    cv_pred = model_cat.predict_proba(val)[:,-1:]\n",
    "    auc = roc_auc_score(y_train[val_idx],cv_pred)\n",
    "    print(f\"auc: {auc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 20:46:38] {1432} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 10-09 20:46:41] {1478} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl: 10-09 20:46:41] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 10-09 20:46:41] {1748} INFO - iteration 0, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:41] {383} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:41] {1865} INFO - Estimated sufficient time budget=525567s. Estimated necessary time budget=9539s.\n",
      "[flaml.automl: 10-09 20:46:41] {1938} INFO -  at 41.0s,\testimator lgbm's best error=0.1984,\tbest estimator lgbm's best error=0.1984\n",
      "[flaml.automl: 10-09 20:46:41] {1748} INFO - iteration 1, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:41] {383} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:42] {1938} INFO -  at 41.5s,\testimator lgbm's best error=0.1896,\tbest estimator lgbm's best error=0.1896\n",
      "[flaml.automl: 10-09 20:46:42] {1748} INFO - iteration 2, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:42] {383} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.0, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:42] {1938} INFO -  at 42.0s,\testimator lgbm's best error=0.1896,\tbest estimator lgbm's best error=0.1896\n",
      "[flaml.automl: 10-09 20:46:42] {1748} INFO - iteration 3, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:42] {383} INFO - trial 1 config: {'n_estimators': 12, 'num_leaves': 4, 'min_child_samples': 25, 'learning_rate': 0.10131160192564638, 'log_max_bin': 10, 'colsample_bytree': 0.7370133750309855, 'reg_alpha': 0.002668211515123386, 'reg_lambda': 0.36111742401339153, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:43] {1938} INFO -  at 42.7s,\testimator lgbm's best error=0.1768,\tbest estimator lgbm's best error=0.1768\n",
      "[flaml.automl: 10-09 20:46:43] {1748} INFO - iteration 4, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:46:43] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:44] {1938} INFO -  at 43.3s,\testimator xgboost's best error=0.1992,\tbest estimator lgbm's best error=0.1768\n",
      "[flaml.automl: 10-09 20:46:44] {1748} INFO - iteration 5, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:44] {383} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 8, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6923970576844015, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:44] {1938} INFO -  at 43.8s,\testimator lgbm's best error=0.1768,\tbest estimator lgbm's best error=0.1768\n",
      "[flaml.automl: 10-09 20:46:44] {1748} INFO - iteration 6, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:44] {383} INFO - trial 1 config: {'n_estimators': 14, 'num_leaves': 5, 'min_child_samples': 15, 'learning_rate': 0.10591441245329958, 'log_max_bin': 9, 'colsample_bytree': 0.6389203895134972, 'reg_alpha': 0.0014132988481787994, 'reg_lambda': 0.022976154325858374, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:45] {1938} INFO -  at 44.5s,\testimator lgbm's best error=0.1718,\tbest estimator lgbm's best error=0.1718\n",
      "[flaml.automl: 10-09 20:46:45] {1748} INFO - iteration 7, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:45] {383} INFO - trial 1 config: {'n_estimators': 12, 'num_leaves': 4, 'min_child_samples': 26, 'learning_rate': 0.10131160192564638, 'log_max_bin': 10, 'colsample_bytree': 0.7370133750309855, 'reg_alpha': 0.002668211515123386, 'reg_lambda': 0.36111742401339153, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:46] {1938} INFO -  at 45.2s,\testimator lgbm's best error=0.1718,\tbest estimator lgbm's best error=0.1718\n",
      "[flaml.automl: 10-09 20:46:46] {1748} INFO - iteration 8, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:46] {383} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 6, 'min_child_samples': 20, 'learning_rate': 0.19173807345245308, 'log_max_bin': 9, 'colsample_bytree': 0.7082741990160921, 'reg_alpha': 0.012553125619676949, 'reg_lambda': 0.1186494209766889, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:46] {1938} INFO -  at 45.7s,\testimator lgbm's best error=0.1718,\tbest estimator lgbm's best error=0.1718\n",
      "[flaml.automl: 10-09 20:46:46] {1748} INFO - iteration 9, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:46] {383} INFO - trial 1 config: {'n_estimators': 53, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.05850618274888138, 'log_max_bin': 10, 'colsample_bytree': 0.5695665800109022, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00444927302013027, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:47] {1938} INFO -  at 46.5s,\testimator lgbm's best error=0.1709,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:47] {1748} INFO - iteration 10, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:46:47] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.8156120279609143, 'learning_rate': 0.03859136192132082, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180926, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:48] {1938} INFO -  at 47.2s,\testimator xgboost's best error=0.1992,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:48] {1748} INFO - iteration 11, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:46:48] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.2620811530815943, 'learning_rate': 0.2591253457286053, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.1809691794829294, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:48] {1938} INFO -  at 47.8s,\testimator xgboost's best error=0.1956,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:48] {1748} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:46:48] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:48] {1938} INFO -  at 48.1s,\testimator extra_tree's best error=0.1977,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:48] {1748} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:46:48] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9692029582222275, 'max_leaves': 13, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:49] {1938} INFO -  at 48.3s,\testimator extra_tree's best error=0.1859,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:49] {1748} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:46:49] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 4, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:49] {1938} INFO -  at 48.5s,\testimator extra_tree's best error=0.1859,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:49] {1748} INFO - iteration 15, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:49] {383} INFO - trial 1 config: {'n_estimators': 15, 'num_leaves': 4, 'min_child_samples': 13, 'learning_rate': 0.1409664384951717, 'log_max_bin': 10, 'colsample_bytree': 0.6657052074144151, 'reg_alpha': 0.0013805492389047578, 'reg_lambda': 0.006107078007733911, 'FLAML_sample_size': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 20:46:50] {1938} INFO -  at 49.2s,\testimator lgbm's best error=0.1709,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:50] {1748} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:46:50] {383} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.639099828735494, 'max_leaves': 11, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:50] {1938} INFO -  at 49.5s,\testimator extra_tree's best error=0.1859,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:50] {1748} INFO - iteration 17, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:46:50] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:51] {1938} INFO -  at 50.1s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1709\n",
      "[flaml.automl: 10-09 20:46:51] {1748} INFO - iteration 18, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:51] {383} INFO - trial 1 config: {'n_estimators': 189, 'num_leaves': 20, 'min_child_samples': 9, 'learning_rate': 0.024282186997032957, 'log_max_bin': 10, 'colsample_bytree': 0.47342795260738935, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.003241489691566039, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:53] {1938} INFO -  at 52.8s,\testimator lgbm's best error=0.1624,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:46:53] {1748} INFO - iteration 19, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:46:53] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9692029582222275, 'max_leaves': 13, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:54] {1938} INFO -  at 53.6s,\testimator rf's best error=0.1815,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:46:54] {1748} INFO - iteration 20, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:46:54] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9999999999999999, 'max_leaves': 4, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:54] {1938} INFO -  at 54.1s,\testimator rf's best error=0.1815,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:46:54] {1748} INFO - iteration 21, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:46:54] {383} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.639099828735494, 'max_leaves': 11, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:55] {1938} INFO -  at 55.1s,\testimator rf's best error=0.1805,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:46:55] {1748} INFO - iteration 22, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:55] {383} INFO - trial 1 config: {'n_estimators': 257, 'num_leaves': 25, 'min_child_samples': 7, 'learning_rate': 0.10577750092292157, 'log_max_bin': 10, 'colsample_bytree': 0.40989107964524396, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0009765625, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:46:59] {1938} INFO -  at 58.5s,\testimator lgbm's best error=0.1624,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:46:59] {1748} INFO - iteration 23, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:46:59] {383} INFO - trial 1 config: {'n_estimators': 139, 'num_leaves': 16, 'min_child_samples': 11, 'learning_rate': 0.005574196783005176, 'log_max_bin': 9, 'colsample_bytree': 0.5369648255695347, 'reg_alpha': 0.001538995396757784, 'reg_lambda': 0.01705653951856333, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:00] {1938} INFO -  at 60.1s,\testimator lgbm's best error=0.1624,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:47:00] {1748} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:47:00] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 16, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:01] {1938} INFO -  at 60.3s,\testimator extra_tree's best error=0.1859,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:47:01] {1748} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:47:01] {383} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.9662106723461057, 'max_leaves': 7, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:01] {1938} INFO -  at 60.6s,\testimator extra_tree's best error=0.1813,\tbest estimator lgbm's best error=0.1624\n",
      "[flaml.automl: 10-09 20:47:01] {1748} INFO - iteration 26, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:01] {383} INFO - trial 1 config: {'n_estimators': 318, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.04519994067959539, 'log_max_bin': 10, 'colsample_bytree': 0.541558149982507, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011560290084572896, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:03] {1938} INFO -  at 62.4s,\testimator lgbm's best error=0.1588,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:03] {1748} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:47:03] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.969202958222227, 'max_leaves': 13, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:03] {1938} INFO -  at 62.6s,\testimator extra_tree's best error=0.1813,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:03] {1748} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:47:03] {383} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.8201393707452405, 'max_leaves': 13, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:03] {1938} INFO -  at 63.0s,\testimator extra_tree's best error=0.1810,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:03] {1748} INFO - iteration 29, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:03] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106968, 'learning_rate': 1.0, 'subsample': 0.8513627344387319, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.2790165919053837, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:04] {1938} INFO -  at 63.7s,\testimator xgboost's best error=0.1750,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:04] {1748} INFO - iteration 30, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:04] {383} INFO - trial 1 config: {'n_estimators': 189, 'num_leaves': 19, 'min_child_samples': 9, 'learning_rate': 0.024282186997032957, 'log_max_bin': 9, 'colsample_bytree': 0.4734279526073894, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.0032414896915660394, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:06] {1938} INFO -  at 65.8s,\testimator lgbm's best error=0.1588,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:06] {1748} INFO - iteration 31, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:06] {383} INFO - trial 1 config: {'n_estimators': 276, 'num_leaves': 16, 'min_child_samples': 7, 'learning_rate': 0.17907552667096496, 'log_max_bin': 10, 'colsample_bytree': 0.6290920542071692, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00593849681857357, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:09] {1938} INFO -  at 69.0s,\testimator lgbm's best error=0.1588,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:09] {1748} INFO - iteration 32, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:09] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.2620811530815941, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.1809691794829294, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:10] {1938} INFO -  at 69.6s,\testimator xgboost's best error=0.1750,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:10] {1748} INFO - iteration 33, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:10] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.5873610441060624, 'learning_rate': 0.5305016568114994, 'subsample': 0.8132820472645405, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8110207792444197, 'reg_alpha': 0.002464557255174736, 'reg_lambda': 0.6369900700728733, 'FLAML_sample_size': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 20:47:11] {1938} INFO -  at 70.2s,\testimator xgboost's best error=0.1750,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:11] {1748} INFO - iteration 34, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:11] {383} INFO - trial 1 config: {'n_estimators': 367, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.011408787540202704, 'log_max_bin': 9, 'colsample_bytree': 0.4540242457578447, 'reg_alpha': 0.001858538296879656, 'reg_lambda': 0.022504063052032567, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:12] {1938} INFO -  at 71.7s,\testimator lgbm's best error=0.1588,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:12] {1748} INFO - iteration 35, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:12] {383} INFO - trial 1 config: {'n_estimators': 12, 'max_leaves': 4, 'min_child_weight': 5.909231502320289, 'learning_rate': 1.0, 'subsample': 0.8894434216129233, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013605736901132325, 'reg_lambda': 0.12221581185651631, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:13] {1938} INFO -  at 72.6s,\testimator xgboost's best error=0.1685,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:13] {1748} INFO - iteration 36, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:13] {383} INFO - trial 1 config: {'n_estimators': 23, 'max_leaves': 4, 'min_child_weight': 12.035965728320857, 'learning_rate': 1.0, 'subsample': 0.9814787163243814, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022085340760961856, 'reg_lambda': 0.5460627024738886, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:14] {1938} INFO -  at 73.6s,\testimator xgboost's best error=0.1685,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:14] {1748} INFO - iteration 37, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:47:14] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.9692029582222269, 'max_leaves': 13, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:15] {1938} INFO -  at 74.6s,\testimator rf's best error=0.1805,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:15] {1748} INFO - iteration 38, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:15] {383} INFO - trial 1 config: {'n_estimators': 6, 'max_leaves': 6, 'min_child_weight': 2.9012226967254797, 'learning_rate': 0.38946718731417634, 'subsample': 0.7974081269014651, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.02735346069247723, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:16] {1938} INFO -  at 75.5s,\testimator xgboost's best error=0.1685,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:16] {1748} INFO - iteration 39, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:16] {383} INFO - trial 1 config: {'n_estimators': 183, 'num_leaves': 17, 'min_child_samples': 6, 'learning_rate': 0.03975596653027463, 'log_max_bin': 10, 'colsample_bytree': 0.6229741816501054, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.021711381455942185, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:19] {1938} INFO -  at 78.2s,\testimator lgbm's best error=0.1588,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:19] {1748} INFO - iteration 40, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:19] {383} INFO - trial 1 config: {'n_estimators': 12, 'max_leaves': 12, 'min_child_weight': 8.51762938681116, 'learning_rate': 1.0, 'subsample': 0.9233328006239467, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9468117873770695, 'reg_alpha': 0.034996420228767956, 'reg_lambda': 0.616907946147381, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:20] {1938} INFO -  at 79.4s,\testimator xgboost's best error=0.1685,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:20] {1748} INFO - iteration 41, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:47:20] {383} INFO - trial 1 config: {'n_estimators': 12, 'max_leaves': 4, 'min_child_weight': 4.099616849035916, 'learning_rate': 0.8210689282647788, 'subsample': 0.8555540426018998, 'colsample_bylevel': 0.9722620955509288, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.024212209878358374, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:21] {1938} INFO -  at 80.4s,\testimator xgboost's best error=0.1674,\tbest estimator lgbm's best error=0.1588\n",
      "[flaml.automl: 10-09 20:47:21] {1748} INFO - iteration 42, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:21] {383} INFO - trial 1 config: {'n_estimators': 318, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.04519994067959539, 'log_max_bin': 10, 'colsample_bytree': 0.541558149982507, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011560290084572896, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:47:24] {1938} INFO -  at 84.0s,\testimator lgbm's best error=0.1559,\tbest estimator lgbm's best error=0.1559\n",
      "[flaml.automl: 10-09 20:47:24] {1748} INFO - iteration 43, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:47:24] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:31] {1938} INFO -  at 90.8s,\testimator catboost's best error=0.1625,\tbest estimator lgbm's best error=0.1559\n",
      "[flaml.automl: 10-09 20:47:31] {1748} INFO - iteration 44, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:47:31] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.005, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:48] {1938} INFO -  at 107.2s,\testimator catboost's best error=0.1625,\tbest estimator lgbm's best error=0.1559\n",
      "[flaml.automl: 10-09 20:47:48] {1748} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:47:48] {383} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.9662106723461055, 'max_leaves': 7, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:48] {1938} INFO -  at 107.4s,\testimator extra_tree's best error=0.1810,\tbest estimator lgbm's best error=0.1559\n",
      "[flaml.automl: 10-09 20:47:48] {1748} INFO - iteration 46, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:47:48] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.2, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:47:53] {1938} INFO -  at 112.5s,\testimator catboost's best error=0.1625,\tbest estimator lgbm's best error=0.1559\n",
      "[flaml.automl: 10-09 20:47:53] {1748} INFO - iteration 47, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:53] {383} INFO - trial 1 config: {'n_estimators': 151, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.1393134579255229, 'log_max_bin': 10, 'colsample_bytree': 0.6886086717000209, 'reg_alpha': 0.0015564673105246886, 'reg_lambda': 0.007518238049465936, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:47:55] {1938} INFO -  at 115.1s,\testimator lgbm's best error=0.1530,\tbest estimator lgbm's best error=0.1530\n",
      "[flaml.automl: 10-09 20:47:55] {1748} INFO - iteration 48, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:47:55] {383} INFO - trial 1 config: {'n_estimators': 318, 'num_leaves': 9, 'min_child_samples': 8, 'learning_rate': 0.04519994067959539, 'log_max_bin': 9, 'colsample_bytree': 0.541558149982507, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.011560290084572896, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:48:00] {1938} INFO -  at 119.2s,\testimator lgbm's best error=0.1518,\tbest estimator lgbm's best error=0.1518\n",
      "[flaml.automl: 10-09 20:48:00] {1748} INFO - iteration 49, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:48:00] {383} INFO - trial 1 config: {'n_estimators': 635, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.05583890066235157, 'log_max_bin': 10, 'colsample_bytree': 0.5917461624114946, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 0.024788166983858027, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:48:05] {1938} INFO -  at 124.3s,\testimator lgbm's best error=0.1498,\tbest estimator lgbm's best error=0.1498\n",
      "[flaml.automl: 10-09 20:48:05] {1748} INFO - iteration 50, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 10-09 20:48:05] {383} INFO - trial 1 config: {'n_estimators': 318, 'num_leaves': 9, 'min_child_samples': 7, 'learning_rate': 0.04519994067959539, 'log_max_bin': 9, 'colsample_bytree': 0.5415581499825071, 'reg_alpha': 0.0009765625000000002, 'reg_lambda': 0.011560290084572896, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:48:09] {1938} INFO -  at 128.5s,\testimator lgbm's best error=0.1498,\tbest estimator lgbm's best error=0.1498\n",
      "[flaml.automl: 10-09 20:48:09] {1748} INFO - iteration 51, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:48:09] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.005, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:48:24] {1938} INFO -  at 143.9s,\testimator catboost's best error=0.1625,\tbest estimator lgbm's best error=0.1498\n",
      "[flaml.automl: 10-09 20:48:24] {1748} INFO - iteration 52, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:48:24] {383} INFO - trial 1 config: {'n_estimators': 896, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.022644002772085153, 'log_max_bin': 10, 'colsample_bytree': 0.7993632929346922, 'reg_alpha': 0.006311706639004055, 'reg_lambda': 0.04407720096600766, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:48:31] {1938} INFO -  at 151.0s,\testimator lgbm's best error=0.1498,\tbest estimator lgbm's best error=0.1498\n",
      "[flaml.automl: 10-09 20:48:31] {1748} INFO - iteration 53, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:48:31] {383} INFO - trial 1 config: {'n_estimators': 450, 'num_leaves': 11, 'min_child_samples': 3, 'learning_rate': 0.13769574480991154, 'log_max_bin': 10, 'colsample_bytree': 0.3841290318882969, 'reg_alpha': 0.0033202544897837413, 'reg_lambda': 0.0139403866160534, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:48:36] {1938} INFO -  at 155.9s,\testimator lgbm's best error=0.1498,\tbest estimator lgbm's best error=0.1498\n",
      "[flaml.automl: 10-09 20:48:36] {1748} INFO - iteration 54, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:48:36] {383} INFO - trial 1 config: {'n_estimators': 398, 'num_leaves': 23, 'min_child_samples': 2, 'learning_rate': 0.03458946603088143, 'log_max_bin': 10, 'colsample_bytree': 0.5363528058350598, 'reg_alpha': 0.0020145913289276885, 'reg_lambda': 0.04191976542471852, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:48:45] {1938} INFO -  at 164.7s,\testimator lgbm's best error=0.1498,\tbest estimator lgbm's best error=0.1498\n",
      "[flaml.automl: 10-09 20:48:45] {1748} INFO - iteration 55, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:48:45] {383} INFO - trial 1 config: {'n_estimators': 635, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.05583890066235157, 'log_max_bin': 10, 'colsample_bytree': 0.5917461624114946, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 0.024788166983858027, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:49:01] {1938} INFO -  at 180.2s,\testimator lgbm's best error=0.1483,\tbest estimator lgbm's best error=0.1483\n",
      "[flaml.automl: 10-09 20:49:01] {1748} INFO - iteration 56, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:49:01] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:49:12] {1938} INFO -  at 191.6s,\testimator catboost's best error=0.1546,\tbest estimator lgbm's best error=0.1483\n",
      "[flaml.automl: 10-09 20:49:12] {1748} INFO - iteration 57, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:49:12] {383} INFO - trial 1 config: {'n_estimators': 1408, 'num_leaves': 8, 'min_child_samples': 2, 'learning_rate': 0.10346731766418847, 'log_max_bin': 8, 'colsample_bytree': 0.4844437478517832, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.04239386201514041, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:49:36] {1938} INFO -  at 216.0s,\testimator lgbm's best error=0.1470,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:49:36] {1748} INFO - iteration 58, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:49:36] {383} INFO - trial 1 config: {'n_estimators': 635, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.05583890066235157, 'log_max_bin': 10, 'colsample_bytree': 0.5917461624114946, 'reg_alpha': 0.004996244283600559, 'reg_lambda': 0.024788166983858027, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:49:53] {1938} INFO -  at 232.2s,\testimator lgbm's best error=0.1470,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:49:53] {1748} INFO - iteration 59, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:49:53] {383} INFO - trial 1 config: {'n_estimators': 887, 'num_leaves': 4, 'min_child_samples': 2, 'learning_rate': 0.03678976874825619, 'log_max_bin': 7, 'colsample_bytree': 0.4394353947109721, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0055509956130504875, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:50:09] {1938} INFO -  at 248.8s,\testimator lgbm's best error=0.1470,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:50:09] {1748} INFO - iteration 60, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:50:09] {383} INFO - trial 1 config: {'n_estimators': 2236, 'num_leaves': 28, 'min_child_samples': 2, 'learning_rate': 0.29099084307588974, 'log_max_bin': 9, 'colsample_bytree': 0.5294521009925943, 'reg_alpha': 0.0030765362612518877, 'reg_lambda': 0.3237688627123796, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:51:07] {1938} INFO -  at 306.9s,\testimator lgbm's best error=0.1470,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:51:07] {1748} INFO - iteration 61, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:51:07] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.005, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:51:36] {1938} INFO -  at 335.5s,\testimator catboost's best error=0.1546,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:51:36] {1748} INFO - iteration 62, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:51:36] {383} INFO - trial 1 config: {'n_estimators': 550, 'num_leaves': 18, 'min_child_samples': 2, 'learning_rate': 0.12295129919718344, 'log_max_bin': 7, 'colsample_bytree': 0.4258893248498813, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.04091983619403299, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:51:50] {1938} INFO -  at 349.8s,\testimator lgbm's best error=0.1470,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:51:50] {1748} INFO - iteration 63, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:51:50] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.2, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:51:58] {1938} INFO -  at 357.8s,\testimator catboost's best error=0.1533,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:51:58] {1748} INFO - iteration 64, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:51:58] {383} INFO - trial 1 config: {'n_estimators': 6, 'max_leaves': 4, 'min_child_weight': 0.8004506547641225, 'learning_rate': 1.0, 'subsample': 0.6841850532595345, 'colsample_bylevel': 0.9282494375658424, 'colsample_bytree': 1.0, 'reg_alpha': 0.002751960545976165, 'reg_lambda': 0.06995235584736123, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:51:59] {1938} INFO -  at 358.5s,\testimator xgboost's best error=0.1674,\tbest estimator lgbm's best error=0.1470\n",
      "[flaml.automl: 10-09 20:51:59] {1748} INFO - iteration 65, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:51:59] {383} INFO - trial 1 config: {'n_estimators': 1408, 'num_leaves': 8, 'min_child_samples': 2, 'learning_rate': 0.10346731766418847, 'log_max_bin': 8, 'colsample_bytree': 0.4844437478517832, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.04239386201514041, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 20:53:44] {1938} INFO -  at 463.8s,\testimator lgbm's best error=0.1440,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:53:44] {1748} INFO - iteration 66, current learner lrl1\n",
      "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
      "[flaml.tune.tune: 10-09 20:53:44] {383} INFO - trial 1 config: {'C': 1.0, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:53:45] {1938} INFO -  at 464.4s,\testimator lrl1's best error=0.1677,\tbest estimator lgbm's best error=0.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 20:53:45] {1748} INFO - iteration 67, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:53:45] {383} INFO - trial 1 config: {'C': 0.24999999999999997, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:53:45] {1938} INFO -  at 465.0s,\testimator lrl1's best error=0.1674,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:53:45] {1748} INFO - iteration 68, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:53:45] {383} INFO - trial 1 config: {'C': 0.06249999999999999, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:53:46] {1938} INFO -  at 465.5s,\testimator lrl1's best error=0.1666,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:53:46] {1748} INFO - iteration 69, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:53:46] {383} INFO - trial 1 config: {'C': 0.03125, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:53:46] {1938} INFO -  at 466.1s,\testimator lrl1's best error=0.1663,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:53:46] {1748} INFO - iteration 70, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:53:46] {383} INFO - trial 1 config: {'n_estimators': 780, 'num_leaves': 25, 'min_child_samples': 2, 'learning_rate': 0.04241137390339911, 'log_max_bin': 7, 'colsample_bytree': 0.5962744220235071, 'reg_alpha': 0.0024737385712432494, 'reg_lambda': 0.023939594968611286, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 20:55:41] {1938} INFO -  at 580.8s,\testimator lgbm's best error=0.1440,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:41] {1748} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:55:41] {383} INFO - trial 1 config: {'n_estimators': 27, 'max_features': 0.8975857574195617, 'max_leaves': 4, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:42] {1938} INFO -  at 581.3s,\testimator extra_tree's best error=0.1789,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:42] {1748} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:55:42] {383} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.8201393707452399, 'max_leaves': 23, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:42] {1938} INFO -  at 581.9s,\testimator extra_tree's best error=0.1781,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:42] {1748} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:55:42] {383} INFO - trial 1 config: {'n_estimators': 14, 'max_features': 0.6835281373525456, 'max_leaves': 17, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:43] {1938} INFO -  at 582.3s,\testimator extra_tree's best error=0.1781,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:43] {1748} INFO - iteration 74, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:55:43] {383} INFO - trial 1 config: {'C': 0.125, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:43] {1938} INFO -  at 582.8s,\testimator lrl1's best error=0.1663,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:43] {1748} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:55:43] {383} INFO - trial 1 config: {'n_estimators': 39, 'max_features': 0.9840539850365719, 'max_leaves': 32, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:44] {1938} INFO -  at 583.8s,\testimator extra_tree's best error=0.1763,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:44] {1748} INFO - iteration 76, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:55:44] {383} INFO - trial 1 config: {'C': 0.03125, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:55:46] {1938} INFO -  at 585.3s,\testimator lrl1's best error=0.1613,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:46] {1748} INFO - iteration 77, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:55:46] {383} INFO - trial 1 config: {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 20.99674503214921, 'learning_rate': 0.5265964800536566, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9013070887791416, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.008380434083919261, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:47] {1938} INFO -  at 586.4s,\testimator xgboost's best error=0.1674,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:47] {1748} INFO - iteration 78, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:55:47] {383} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 3.449311959729321, 'learning_rate': 1.0, 'subsample': 0.8283637864819567, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.003031643644612933, 'reg_lambda': 0.013358187232581763, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:47] {1938} INFO -  at 587.1s,\testimator xgboost's best error=0.1674,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:47] {1748} INFO - iteration 79, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:55:47] {383} INFO - trial 1 config: {'C': 0.125, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:55:49] {1938} INFO -  at 588.7s,\testimator lrl1's best error=0.1613,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:49] {1748} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:55:49] {383} INFO - trial 1 config: {'n_estimators': 14, 'max_features': 1.0, 'max_leaves': 60, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:55:50] {1938} INFO -  at 589.3s,\testimator extra_tree's best error=0.1763,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:55:50] {1748} INFO - iteration 81, current learner catboost\n",
      "[flaml.tune.tune: 10-09 20:55:50] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.005, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 20:56:18] {1938} INFO -  at 617.3s,\testimator catboost's best error=0.1533,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:18] {1748} INFO - iteration 82, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:56:18] {383} INFO - trial 1 config: {'C': 0.03125, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:56:23] {1938} INFO -  at 623.0s,\testimator lrl1's best error=0.1601,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:23] {1748} INFO - iteration 83, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:56:23] {383} INFO - trial 1 config: {'n_estimators': 38, 'max_leaves': 4, 'min_child_weight': 4.8725248702115245, 'learning_rate': 0.3010028603094627, 'subsample': 0.882744298721843, 'colsample_bylevel': 0.790535831729289, 'colsample_bytree': 0.9550797698873387, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.04388552855164412, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:24] {1938} INFO -  at 624.1s,\testimator xgboost's best error=0.1617,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:24] {1748} INFO - iteration 84, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:56:24] {383} INFO - trial 1 config: {'n_estimators': 21, 'max_leaves': 4, 'min_child_weight': 33.937711291975745, 'learning_rate': 0.18044483230973865, 'subsample': 0.8655164786838745, 'colsample_bylevel': 0.9813763200579734, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.08419969254832448, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:25] {1938} INFO -  at 625.0s,\testimator xgboost's best error=0.1617,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:25] {1748} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:56:25] {383} INFO - trial 1 config: {'n_estimators': 106, 'max_features': 0.9285005685774568, 'max_leaves': 17, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:27] {1938} INFO -  at 626.9s,\testimator extra_tree's best error=0.1763,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:27] {1748} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:56:27] {383} INFO - trial 1 config: {'n_estimators': 30, 'max_features': 1.0, 'max_leaves': 120, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 20:56:28] {1938} INFO -  at 628.0s,\testimator extra_tree's best error=0.1759,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:28] {1748} INFO - iteration 87, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:56:28] {383} INFO - trial 1 config: {'n_estimators': 70, 'max_leaves': 7, 'min_child_weight': 0.6995609811921316, 'learning_rate': 0.5021076012803503, 'subsample': 0.8999721187598114, 'colsample_bylevel': 0.5996953434006045, 'colsample_bytree': 0.8709062981395698, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.022873475638308556, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:30] {1938} INFO -  at 629.7s,\testimator xgboost's best error=0.1617,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:30] {1748} INFO - iteration 88, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:56:30] {383} INFO - trial 1 config: {'n_estimators': 18, 'max_leaves': 4, 'min_child_weight': 6.654536786882862, 'learning_rate': 0.9653613509122261, 'subsample': 0.9931854240555535, 'colsample_bylevel': 0.942779489567657, 'colsample_bytree': 0.9895436611024311, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.10834429454902914, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:31] {1938} INFO -  at 630.7s,\testimator xgboost's best error=0.1617,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:31] {1748} INFO - iteration 89, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 20:56:31] {383} INFO - trial 1 config: {'n_estimators': 82, 'max_leaves': 9, 'min_child_weight': 3.5677161868919356, 'learning_rate': 0.0938536868384695, 'subsample': 0.7723031733881324, 'colsample_bylevel': 0.638292173890921, 'colsample_bytree': 0.9206158786722463, 'reg_alpha': 0.0015245843735931768, 'reg_lambda': 0.017776105555661025, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:33] {1938} INFO -  at 632.6s,\testimator xgboost's best error=0.1614,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:33] {1748} INFO - iteration 90, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:56:33] {383} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.6371266925881748, 'max_leaves': 6, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:34] {1938} INFO -  at 633.8s,\testimator rf's best error=0.1803,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:34] {1748} INFO - iteration 91, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:56:34] {383} INFO - trial 1 config: {'C': 0.125, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 20:56:40] {1938} INFO -  at 639.6s,\testimator lrl1's best error=0.1601,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:40] {1748} INFO - iteration 92, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:56:40] {383} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.6390998287354936, 'max_leaves': 11, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:56:41] {1938} INFO -  at 640.4s,\testimator rf's best error=0.1794,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:56:41] {1748} INFO - iteration 93, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 20:56:41] {383} INFO - trial 1 config: {'C': 0.03125, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 20:57:06] {1938} INFO -  at 665.4s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:57:06] {1748} INFO - iteration 94, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:57:06] {383} INFO - trial 1 config: {'n_estimators': 20, 'max_features': 0.5424809996248549, 'max_leaves': 21, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:57:08] {1938} INFO -  at 667.2s,\testimator rf's best error=0.1760,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:57:08] {1748} INFO - iteration 95, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:57:08] {383} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.6390998287354934, 'max_leaves': 11, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:57:09] {1938} INFO -  at 668.2s,\testimator rf's best error=0.1760,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:57:09] {1748} INFO - iteration 96, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:57:09] {383} INFO - trial 1 config: {'n_estimators': 2541, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.2524201608984915, 'log_max_bin': 9, 'colsample_bytree': 0.3726130736800592, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0750739324919757, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 20:59:08] {1938} INFO -  at 787.2s,\testimator lgbm's best error=0.1440,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:59:08] {1748} INFO - iteration 97, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 20:59:08] {383} INFO - trial 1 config: {'n_estimators': 39, 'max_features': 0.8602442593241234, 'max_leaves': 32, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:59:09] {1938} INFO -  at 788.1s,\testimator extra_tree's best error=0.1759,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:59:09] {1748} INFO - iteration 98, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:59:09] {383} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.5937078944174344, 'max_leaves': 4, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:59:10] {1938} INFO -  at 789.4s,\testimator rf's best error=0.1760,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:59:10] {1748} INFO - iteration 99, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:59:10] {383} INFO - trial 1 config: {'n_estimators': 17, 'max_features': 0.49567411469699973, 'max_leaves': 121, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:59:12] {1938} INFO -  at 791.4s,\testimator rf's best error=0.1760,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:59:12] {1748} INFO - iteration 100, current learner rf\n",
      "[flaml.tune.tune: 10-09 20:59:12] {383} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.45211953047173736, 'max_leaves': 15, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 20:59:13] {1938} INFO -  at 792.3s,\testimator rf's best error=0.1760,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 20:59:13] {1748} INFO - iteration 101, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 20:59:13] {383} INFO - trial 1 config: {'n_estimators': 7895, 'num_leaves': 11, 'min_child_samples': 2, 'learning_rate': 0.1565499699292465, 'log_max_bin': 7, 'colsample_bytree': 0.4959045268857997, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.10644505281225632, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:06:36] {1938} INFO -  at 1235.4s,\testimator lgbm's best error=0.1440,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:06:36] {1748} INFO - iteration 102, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 21:06:36] {383} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.732456001618701, 'max_leaves': 159, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:06:36] {1938} INFO -  at 1236.1s,\testimator extra_tree's best error=0.1759,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:06:36] {1748} INFO - iteration 103, current learner rf\n",
      "[flaml.tune.tune: 10-09 21:06:36] {383} INFO - trial 1 config: {'n_estimators': 34, 'max_features': 0.6509022838427854, 'max_leaves': 29, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:06:40] {1938} INFO -  at 1240.0s,\testimator rf's best error=0.1750,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:06:40] {1748} INFO - iteration 104, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:06:40] {383} INFO - trial 1 config: {'n_estimators': 251, 'num_leaves': 6, 'min_child_samples': 2, 'learning_rate': 0.06838382549329446, 'log_max_bin': 9, 'colsample_bytree': 0.47298296881776664, 'reg_alpha': 0.00596956133069734, 'reg_lambda': 0.016884199773273323, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:07:12] {1938} INFO -  at 1271.5s,\testimator lgbm's best error=0.1440,\tbest estimator lgbm's best error=0.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 21:07:12] {1748} INFO - iteration 105, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:07:12] {383} INFO - trial 1 config: {'n_estimators': 36, 'max_leaves': 4, 'min_child_weight': 5.2132342931040965, 'learning_rate': 0.16181283230671778, 'subsample': 0.8205572182902741, 'colsample_bylevel': 0.7549779317083054, 'colsample_bytree': 0.9782276720362517, 'reg_alpha': 0.00219619032371591, 'reg_lambda': 0.00585416476178816, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:07:13] {1938} INFO -  at 1272.7s,\testimator xgboost's best error=0.1614,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:07:13] {1748} INFO - iteration 106, current learner rf\n",
      "[flaml.tune.tune: 10-09 21:07:13] {383} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.6898466279522427, 'max_leaves': 55, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:07:16] {1938} INFO -  at 1275.3s,\testimator rf's best error=0.1750,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:07:16] {1748} INFO - iteration 107, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:07:16] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.2, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:07:23] {1938} INFO -  at 1282.9s,\testimator catboost's best error=0.1533,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:07:23] {1748} INFO - iteration 108, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 21:07:23] {383} INFO - trial 1 config: {'n_estimators': 59, 'max_features': 1.0, 'max_leaves': 91, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:07:25] {1938} INFO -  at 1284.7s,\testimator extra_tree's best error=0.1749,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:07:25] {1748} INFO - iteration 109, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:07:25] {383} INFO - trial 1 config: {'n_estimators': 186, 'max_leaves': 64, 'min_child_weight': 2.441593466659982, 'learning_rate': 0.054436439975767054, 'subsample': 0.7240491284859907, 'colsample_bylevel': 0.5216064160735365, 'colsample_bytree': 0.8630040853082407, 'reg_alpha': 0.001058358871316641, 'reg_lambda': 0.053976944890338774, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:07:36] {1938} INFO -  at 1296.1s,\testimator xgboost's best error=0.1614,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:07:36] {1748} INFO - iteration 110, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 21:07:36] {383} INFO - trial 1 config: {'n_estimators': 57, 'max_features': 1.0, 'max_leaves': 141, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:07:39] {1938} INFO -  at 1298.6s,\testimator extra_tree's best error=0.1749,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:07:39] {1748} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 21:07:39] {383} INFO - trial 1 config: {'n_estimators': 61, 'max_features': 0.6474332373706322, 'max_leaves': 59, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:07:40] {1938} INFO -  at 1299.7s,\testimator extra_tree's best error=0.1749,\tbest estimator lgbm's best error=0.1440\n",
      "[flaml.automl: 10-09 21:07:40] {1748} INFO - iteration 112, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:07:40] {383} INFO - trial 1 config: {'n_estimators': 3100, 'num_leaves': 7, 'min_child_samples': 4, 'learning_rate': 0.05272400314432986, 'log_max_bin': 9, 'colsample_bytree': 0.46739000988362633, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.15861732590335134, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:11:07] {1938} INFO -  at 1506.3s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:11:07] {1748} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 21:11:07] {383} INFO - trial 1 config: {'n_estimators': 71, 'max_features': 1.0, 'max_leaves': 61, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:11:09] {1938} INFO -  at 1508.4s,\testimator extra_tree's best error=0.1749,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:11:09] {1748} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 21:11:09] {383} INFO - trial 1 config: {'n_estimators': 49, 'max_features': 0.9486713824818461, 'max_leaves': 135, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:11:10] {1938} INFO -  at 1510.0s,\testimator extra_tree's best error=0.1748,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:11:10] {1748} INFO - iteration 115, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 21:11:10] {383} INFO - trial 1 config: {'C': 0.125, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:11:39] {1938} INFO -  at 1538.7s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:11:39] {1748} INFO - iteration 116, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:11:39] {383} INFO - trial 1 config: {'n_estimators': 1408, 'num_leaves': 8, 'min_child_samples': 2, 'learning_rate': 0.10346731766418847, 'log_max_bin': 8, 'colsample_bytree': 0.4844437478517832, 'reg_alpha': 0.008948061409181867, 'reg_lambda': 0.04239386201514041, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:13:20] {1938} INFO -  at 1639.2s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:13:20] {1748} INFO - iteration 117, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:13:20] {383} INFO - trial 1 config: {'n_estimators': 7837, 'num_leaves': 38, 'min_child_samples': 4, 'learning_rate': 0.0645247911040952, 'log_max_bin': 10, 'colsample_bytree': 0.40441012188830583, 'reg_alpha': 0.0034922118383222253, 'reg_lambda': 0.039301960589841624, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:22:57] {1938} INFO -  at 2217.0s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:22:57] {1748} INFO - iteration 118, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:22:57] {383} INFO - trial 1 config: {'n_estimators': 82, 'max_leaves': 9, 'min_child_weight': 3.5677161868919356, 'learning_rate': 0.0938536868384695, 'subsample': 0.7723031733881324, 'colsample_bylevel': 0.638292173890921, 'colsample_bytree': 0.9206158786722463, 'reg_alpha': 0.0015245843735931768, 'reg_lambda': 0.017776105555661025, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:23:02] {1938} INFO -  at 2221.4s,\testimator xgboost's best error=0.1567,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:23:02] {1748} INFO - iteration 119, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:23:02] {383} INFO - trial 1 config: {'n_estimators': 75, 'max_leaves': 4, 'min_child_weight': 2.590945629170087, 'learning_rate': 0.2482602440620601, 'subsample': 0.786256644634432, 'colsample_bylevel': 0.6657980934753858, 'colsample_bytree': 0.8699463805787385, 'reg_alpha': 0.021823817486957747, 'reg_lambda': 0.0023397102900589804, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:23:05] {1938} INFO -  at 2224.9s,\testimator xgboost's best error=0.1536,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:23:05] {1748} INFO - iteration 120, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:23:05] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.2, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 21:23:37] {1938} INFO -  at 2256.2s,\testimator catboost's best error=0.1480,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:23:37] {1748} INFO - iteration 121, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:23:37] {383} INFO - trial 1 config: {'n_estimators': 82, 'max_leaves': 9, 'min_child_weight': 3.5677161868919356, 'learning_rate': 0.0938536868384695, 'subsample': 0.7723031733881324, 'colsample_bylevel': 0.638292173890921, 'colsample_bytree': 0.9206158786722463, 'reg_alpha': 0.0015245843735931766, 'reg_lambda': 0.017776105555661025, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:23:40] {1938} INFO -  at 2259.9s,\testimator xgboost's best error=0.1536,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:23:40] {1748} INFO - iteration 122, current learner xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 10-09 21:23:40] {383} INFO - trial 1 config: {'n_estimators': 26, 'max_leaves': 12, 'min_child_weight': 0.8405355447109188, 'learning_rate': 0.12301817775981962, 'subsample': 0.8446126454756901, 'colsample_bylevel': 0.7602940426034086, 'colsample_bytree': 0.9561374252596755, 'reg_alpha': 0.004803047591271664, 'reg_lambda': 0.008862776054047674, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:23:43] {1938} INFO -  at 2262.5s,\testimator xgboost's best error=0.1536,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:23:43] {1748} INFO - iteration 123, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:23:43] {383} INFO - trial 1 config: {'n_estimators': 218, 'max_leaves': 4, 'min_child_weight': 7.986573911784238, 'learning_rate': 0.5010084680500312, 'subsample': 0.7279006437931739, 'colsample_bylevel': 0.5713021443473629, 'colsample_bytree': 0.7837553358978016, 'reg_alpha': 0.0991618343673214, 'reg_lambda': 0.0009765625, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:23:48] {1938} INFO -  at 2267.9s,\testimator xgboost's best error=0.1536,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:23:48] {1748} INFO - iteration 124, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:23:48] {383} INFO - trial 1 config: {'n_estimators': 19, 'max_leaves': 4, 'min_child_weight': 0.5969858568929752, 'learning_rate': 0.32993806238719625, 'subsample': 0.7465629148307283, 'colsample_bylevel': 0.5478053384379661, 'colsample_bytree': 0.8738505525634098, 'reg_alpha': 0.0036927536290320678, 'reg_lambda': 0.0009765625, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:23:50] {1938} INFO -  at 2269.9s,\testimator xgboost's best error=0.1536,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:23:50] {1748} INFO - iteration 125, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:23:50] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.18865783582261322, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 21:24:09] {1938} INFO -  at 2288.2s,\testimator catboost's best error=0.1475,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:24:09] {1748} INFO - iteration 126, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:24:09] {383} INFO - trial 1 config: {'n_estimators': 1226, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.04308143366289609, 'log_max_bin': 8, 'colsample_bytree': 0.5303698978789468, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6401577860019771, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:25:34] {1938} INFO -  at 2373.6s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:25:34] {1748} INFO - iteration 127, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:25:34] {383} INFO - trial 1 config: {'n_estimators': 681, 'num_leaves': 5, 'min_child_samples': 3, 'learning_rate': 0.1399610010759889, 'log_max_bin': 7, 'colsample_bytree': 0.4491471366582007, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.2203462874803145, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:26:25] {1938} INFO -  at 2424.9s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:26:25] {1748} INFO - iteration 128, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:26:25] {383} INFO - trial 1 config: {'n_estimators': 14120, 'num_leaves': 9, 'min_child_samples': 5, 'learning_rate': 0.019861393432403784, 'log_max_bin': 10, 'colsample_bytree': 0.4856328831090519, 'reg_alpha': 0.001975258376030875, 'reg_lambda': 0.11418143851857587, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:40:56] {1938} INFO -  at 3295.3s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:40:56] {1748} INFO - iteration 129, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:40:56] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.005, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 21:41:59] {1938} INFO -  at 3358.7s,\testimator catboost's best error=0.1475,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:41:59] {1748} INFO - iteration 130, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:41:59] {383} INFO - trial 1 config: {'n_estimators': 294, 'max_leaves': 11, 'min_child_weight': 11.244821256325093, 'learning_rate': 0.18680217837196528, 'subsample': 0.8259503744381358, 'colsample_bylevel': 0.7837908485128056, 'colsample_bytree': 0.8660422085940672, 'reg_alpha': 0.1289766547000547, 'reg_lambda': 0.0056205318197642285, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 21:42:10] {1938} INFO -  at 3369.2s,\testimator xgboost's best error=0.1536,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:42:10] {1748} INFO - iteration 131, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 21:42:10] {383} INFO - trial 1 config: {'n_estimators': 75, 'max_leaves': 4, 'min_child_weight': 2.590945629170087, 'learning_rate': 0.2482602440620601, 'subsample': 0.786256644634432, 'colsample_bylevel': 0.6657980934753858, 'colsample_bytree': 0.8699463805787385, 'reg_alpha': 0.021823817486957747, 'reg_lambda': 0.0023397102900589804, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 21:42:19] {1938} INFO -  at 3379.0s,\testimator xgboost's best error=0.1532,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:42:19] {1748} INFO - iteration 132, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:42:19] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.18865783582261322, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:44:37] {1938} INFO -  at 3516.9s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:44:37] {1748} INFO - iteration 133, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:44:37] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.024238024636898205, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:49:26] {1938} INFO -  at 3805.7s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:49:26] {1748} INFO - iteration 134, current learner rf\n",
      "[flaml.tune.tune: 10-09 21:49:26] {383} INFO - trial 1 config: {'n_estimators': 93, 'max_features': 0.6141564892031108, 'max_leaves': 15, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:49:32] {1938} INFO -  at 3811.7s,\testimator rf's best error=0.1748,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:49:32] {1748} INFO - iteration 135, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:49:32] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.2, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:50:49] {1938} INFO -  at 3888.8s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:50:49] {1748} INFO - iteration 136, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:50:49] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.011068265745045599, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:56:36] {1938} INFO -  at 4235.2s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:56:36] {1748} INFO - iteration 137, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 21:56:36] {383} INFO - trial 1 config: {'C': 0.11510958592923767, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 21:57:06] {1938} INFO -  at 4265.2s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:57:06] {1748} INFO - iteration 138, current learner catboost\n",
      "[flaml.tune.tune: 10-09 21:57:06] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.008704574594185277, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 21:57:20] {1938} INFO -  at 4279.4s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 21:57:20] {1748} INFO - iteration 139, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 21:57:20] {383} INFO - trial 1 config: {'n_estimators': 5508, 'num_leaves': 17, 'min_child_samples': 5, 'learning_rate': 0.06949056784155684, 'log_max_bin': 9, 'colsample_bytree': 0.30664801885817755, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.26615997582812956, 'FLAML_sample_size': 720000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 22:02:13] {1938} INFO -  at 4572.9s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:02:13] {1748} INFO - iteration 140, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 22:02:13] {383} INFO - trial 1 config: {'n_estimators': 57, 'max_leaves': 4, 'min_child_weight': 0.8293529703641633, 'learning_rate': 0.1079507503768468, 'subsample': 0.8814502105580743, 'colsample_bylevel': 0.46872050677193183, 'colsample_bytree': 0.8983390764033905, 'reg_alpha': 0.007451941216498744, 'reg_lambda': 0.0009765625, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 22:02:22] {1938} INFO -  at 4581.2s,\testimator xgboost's best error=0.1532,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:02:22] {1748} INFO - iteration 141, current learner rf\n",
      "[flaml.tune.tune: 10-09 22:02:22] {383} INFO - trial 1 config: {'n_estimators': 71, 'max_features': 0.7139326796387357, 'max_leaves': 56, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 22:02:28] {1938} INFO -  at 4587.3s,\testimator rf's best error=0.1746,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:02:28] {1748} INFO - iteration 142, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 22:02:28] {383} INFO - trial 1 config: {'n_estimators': 98, 'max_leaves': 7, 'min_child_weight': 8.094260819211808, 'learning_rate': 0.570937659688308, 'subsample': 0.6910630787107898, 'colsample_bylevel': 0.8628756801788398, 'colsample_bytree': 0.8415536847540865, 'reg_alpha': 0.0639134147555474, 'reg_lambda': 0.006017988391890761, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 22:02:39] {1938} INFO -  at 4598.4s,\testimator xgboost's best error=0.1511,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:02:39] {1748} INFO - iteration 143, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 22:02:39] {383} INFO - trial 1 config: {'n_estimators': 19, 'max_leaves': 7, 'min_child_weight': 4.184018037871787, 'learning_rate': 1.0, 'subsample': 0.6395586194587763, 'colsample_bylevel': 0.7537498224197077, 'colsample_bytree': 0.7212843240619822, 'reg_alpha': 0.24447105709500094, 'reg_lambda': 0.013343310583321501, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 22:02:45] {1938} INFO -  at 4604.2s,\testimator xgboost's best error=0.1511,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:02:45] {1748} INFO - iteration 144, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 22:02:45] {383} INFO - trial 1 config: {'n_estimators': 498, 'max_leaves': 7, 'min_child_weight': 15.658885219039995, 'learning_rate': 0.27174891524285655, 'subsample': 0.7425675379628032, 'colsample_bylevel': 0.972001537937972, 'colsample_bytree': 0.9618230454461908, 'reg_alpha': 0.016709235989957008, 'reg_lambda': 0.0027141828153352315, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 22:03:21] {1938} INFO -  at 4640.7s,\testimator xgboost's best error=0.1508,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:03:21] {1748} INFO - iteration 145, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 22:03:21] {383} INFO - trial 1 config: {'n_estimators': 340, 'max_leaves': 43, 'min_child_weight': 22.880812375844407, 'learning_rate': 0.21225533134584557, 'subsample': 0.7990301035160632, 'colsample_bylevel': 0.8399750524117838, 'colsample_bytree': 0.9738576563999158, 'reg_alpha': 0.002496592715539567, 'reg_lambda': 0.0071364197246481745, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 22:04:05] {1938} INFO -  at 4684.5s,\testimator xgboost's best error=0.1508,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:04:05] {1748} INFO - iteration 146, current learner catboost\n",
      "[flaml.tune.tune: 10-09 22:04:05] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.2, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 22:04:10] {1938} INFO -  at 4690.1s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:04:10] {1748} INFO - iteration 147, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 22:04:10] {383} INFO - trial 1 config: {'n_estimators': 1745, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.04000284634170039, 'log_max_bin': 9, 'colsample_bytree': 0.6281320009090752, 'reg_alpha': 0.013575172218183634, 'reg_lambda': 0.09452757124150202, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 22:06:22] {1938} INFO -  at 4821.8s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:06:22] {1748} INFO - iteration 148, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 22:06:22] {383} INFO - trial 1 config: {'n_estimators': 760, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.040092757018942424, 'log_max_bin': 8, 'colsample_bytree': 0.3668528861053084, 'reg_alpha': 0.001035184753971376, 'reg_lambda': 1.56170220336556, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 22:07:23] {1938} INFO -  at 4882.3s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:07:23] {1748} INFO - iteration 149, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 22:07:23] {383} INFO - trial 1 config: {'n_estimators': 12642, 'num_leaves': 16, 'min_child_samples': 4, 'learning_rate': 0.0693347306160546, 'log_max_bin': 10, 'colsample_bytree': 0.5679271336619441, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.016110277633283647, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 22:21:17] {1938} INFO -  at 5716.8s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:21:17] {1748} INFO - iteration 150, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 22:21:17] {383} INFO - trial 1 config: {'n_estimators': 489, 'num_leaves': 5, 'min_child_samples': 6, 'learning_rate': 0.06573607355021807, 'log_max_bin': 8, 'colsample_bytree': 0.4712487125305498, 'reg_alpha': 0.0019352652586410964, 'reg_lambda': 0.8677891409864591, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 22:22:00] {1938} INFO -  at 5759.7s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:22:00] {1748} INFO - iteration 151, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 22:22:00] {383} INFO - trial 1 config: {'n_estimators': 19633, 'num_leaves': 9, 'min_child_samples': 2, 'learning_rate': 0.04228759579684514, 'log_max_bin': 10, 'colsample_bytree': 0.4635313072367028, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.02899259150457906, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 22:39:50] {1938} INFO -  at 6830.0s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:39:50] {1748} INFO - iteration 152, current learner rf\n",
      "[flaml.tune.tune: 10-09 22:39:50] {383} INFO - trial 1 config: {'n_estimators': 93, 'max_features': 0.6141564892031107, 'max_leaves': 15, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 22:39:58] {1938} INFO -  at 6837.2s,\testimator rf's best error=0.1746,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:39:58] {1748} INFO - iteration 153, current learner catboost\n",
      "[flaml.tune.tune: 10-09 22:39:58] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.02686247362637901, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 22:40:09] {1938} INFO -  at 6848.7s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:40:09] {1748} INFO - iteration 154, current learner catboost\n",
      "[flaml.tune.tune: 10-09 22:40:09] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.02686247362637901, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-09 22:40:32] {1938} INFO -  at 6871.9s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 22:40:32] {1748} INFO - iteration 155, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 22:40:32] {383} INFO - trial 1 config: {'n_estimators': 481, 'num_leaves': 4, 'min_child_samples': 5, 'learning_rate': 0.07776499641514874, 'log_max_bin': 9, 'colsample_bytree': 0.5200818994512986, 'reg_alpha': 0.004756653941987421, 'reg_lambda': 0.3613584426618541, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 22:41:16] {1938} INFO -  at 6915.2s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 22:41:16] {1748} INFO - iteration 156, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 22:41:16] {383} INFO - trial 1 config: {'n_estimators': 19979, 'num_leaves': 19, 'min_child_samples': 3, 'learning_rate': 0.03574642365728692, 'log_max_bin': 9, 'colsample_bytree': 0.414698120315954, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0696246527171174, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:00:35] {1938} INFO -  at 8074.2s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:00:35] {1748} INFO - iteration 157, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 23:00:35] {383} INFO - trial 1 config: {'C': 0.10977747256264136, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:01:00] {1938} INFO -  at 8099.6s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:01:00] {1748} INFO - iteration 158, current learner catboost\n",
      "[flaml.tune.tune: 10-09 23:01:00] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.02686247362637901, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 23:01:54] {1938} INFO -  at 8154.0s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:01:54] {1748} INFO - iteration 159, current learner rf\n",
      "[flaml.tune.tune: 10-09 23:01:54] {383} INFO - trial 1 config: {'n_estimators': 36, 'max_features': 0.5229242759531132, 'max_leaves': 74, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:01:57] {1938} INFO -  at 8157.0s,\testimator rf's best error=0.1744,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:01:57] {1748} INFO - iteration 160, current learner catboost\n",
      "[flaml.tune.tune: 10-09 23:01:57] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.2, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 23:02:15] {1938} INFO -  at 8174.2s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:02:15] {1748} INFO - iteration 161, current learner catboost\n",
      "[flaml.tune.tune: 10-09 23:02:15] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.005, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 23:02:56] {1938} INFO -  at 8215.8s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:02:56] {1748} INFO - iteration 162, current learner rf\n",
      "[flaml.tune.tune: 10-09 23:02:56] {383} INFO - trial 1 config: {'n_estimators': 70, 'max_features': 0.7139326796387354, 'max_leaves': 56, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:03:05] {1938} INFO -  at 8225.1s,\testimator rf's best error=0.1731,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:03:05] {1748} INFO - iteration 163, current learner rf\n",
      "[flaml.tune.tune: 10-09 23:03:05] {383} INFO - trial 1 config: {'n_estimators': 68, 'max_features': 1.0, 'max_leaves': 87, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:03:20] {1938} INFO -  at 8239.8s,\testimator rf's best error=0.1731,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:03:20] {1748} INFO - iteration 164, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 23:03:20] {383} INFO - trial 1 config: {'n_estimators': 104, 'max_features': 0.8015166488603687, 'max_leaves': 96, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:03:23] {1938} INFO -  at 8242.5s,\testimator extra_tree's best error=0.1743,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:03:23] {1748} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 23:03:23] {383} INFO - trial 1 config: {'n_estimators': 49, 'max_features': 0.9486713824818459, 'max_leaves': 135, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:03:25] {1938} INFO -  at 8244.2s,\testimator extra_tree's best error=0.1743,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:03:25] {1748} INFO - iteration 166, current learner rf\n",
      "[flaml.tune.tune: 10-09 23:03:25] {383} INFO - trial 1 config: {'n_estimators': 72, 'max_features': 0.46222374604319677, 'max_leaves': 36, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:03:28] {1938} INFO -  at 8248.0s,\testimator rf's best error=0.1724,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:03:28] {1748} INFO - iteration 167, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:03:28] {383} INFO - trial 1 config: {'n_estimators': 729, 'max_leaves': 4, 'min_child_weight': 10.716432715559131, 'learning_rate': 0.3479181063082146, 'subsample': 0.6861049724095432, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9497884344924657, 'reg_alpha': 0.11183184410907565, 'reg_lambda': 0.0010322807008698283, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 23:04:15] {1938} INFO -  at 8294.2s,\testimator xgboost's best error=0.1508,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:04:15] {1748} INFO - iteration 168, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 23:04:15] {383} INFO - trial 1 config: {'n_estimators': 148, 'max_features': 0.5462036854749484, 'max_leaves': 68, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:04:17] {1938} INFO -  at 8296.6s,\testimator extra_tree's best error=0.1733,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:04:17] {1748} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 23:04:17] {383} INFO - trial 1 config: {'n_estimators': 104, 'max_features': 0.8015166488603683, 'max_leaves': 97, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:04:19] {1938} INFO -  at 8299.0s,\testimator extra_tree's best error=0.1733,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:04:19] {1748} INFO - iteration 170, current learner rf\n",
      "[flaml.tune.tune: 10-09 23:04:19] {383} INFO - trial 1 config: {'n_estimators': 87, 'max_features': 0.48723272840165155, 'max_leaves': 24, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:04:24] {1938} INFO -  at 8303.3s,\testimator rf's best error=0.1724,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:04:24] {1748} INFO - iteration 171, current learner lgbm\n",
      "[flaml.tune.tune: 10-09 23:04:24] {383} INFO - trial 1 config: {'n_estimators': 22245, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.02239134677535388, 'log_max_bin': 10, 'colsample_bytree': 0.48764904222149097, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.0410161900139353, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:23:10] {1938} INFO -  at 9429.1s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:23:10] {1748} INFO - iteration 172, current learner rf\n",
      "[flaml.tune.tune: 10-09 23:23:10] {383} INFO - trial 1 config: {'n_estimators': 59, 'max_features': 0.4384984401747371, 'max_leaves': 53, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:23:15] {1938} INFO -  at 9434.3s,\testimator rf's best error=0.1724,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:23:15] {1748} INFO - iteration 173, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 23:23:15] {383} INFO - trial 1 config: {'n_estimators': 228, 'max_features': 0.6430030483478867, 'max_leaves': 18, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:23:18] {1938} INFO -  at 9437.2s,\testimator extra_tree's best error=0.1733,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:23:18] {1748} INFO - iteration 174, current learner extra_tree\n",
      "[flaml.tune.tune: 10-09 23:23:18] {383} INFO - trial 1 config: {'n_estimators': 96, 'max_features': 0.4639767521988556, 'max_leaves': 253, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:23:19] {1938} INFO -  at 9439.0s,\testimator extra_tree's best error=0.1729,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:23:19] {1748} INFO - iteration 175, current learner catboost\n",
      "[flaml.tune.tune: 10-09 23:23:19] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.0051980927473620694, 'FLAML_sample_size': 160000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-09 23:23:57] {1938} INFO -  at 9477.0s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:23:57] {1748} INFO - iteration 176, current learner catboost\n",
      "[flaml.tune.tune: 10-09 23:23:57] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.2, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:26:08] {1938} INFO -  at 9607.5s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:26:08] {1748} INFO - iteration 177, current learner lrl1\n",
      "[flaml.tune.tune: 10-09 23:26:08] {383} INFO - trial 1 config: {'C': 0.10519879405645226, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:26:37] {1938} INFO -  at 9636.5s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:26:37] {1748} INFO - iteration 178, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:26:37] {383} INFO - trial 1 config: {'n_estimators': 948, 'max_leaves': 6, 'min_child_weight': 65.3878432693403, 'learning_rate': 0.15678235810427021, 'subsample': 0.7973032731346197, 'colsample_bylevel': 0.9580885965276406, 'colsample_bytree': 0.8327656424799896, 'reg_alpha': 0.04903043278436087, 'reg_lambda': 0.0387137276240941, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 23:27:43] {1938} INFO -  at 9702.8s,\testimator xgboost's best error=0.1472,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:27:43] {1748} INFO - iteration 179, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:27:43] {383} INFO - trial 1 config: {'n_estimators': 6075, 'max_leaves': 6, 'min_child_weight': 95.29578445868971, 'learning_rate': 0.34512424662212904, 'subsample': 0.7343719622360335, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7232490167604608, 'reg_alpha': 0.016864431180194775, 'reg_lambda': 0.031475242818834785, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-09 23:33:55] {1938} INFO -  at 10074.3s,\testimator xgboost's best error=0.1472,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:33:55] {1748} INFO - iteration 180, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:33:55] {383} INFO - trial 1 config: {'n_estimators': 948, 'max_leaves': 6, 'min_child_weight': 65.3878432693403, 'learning_rate': 0.15678235810427021, 'subsample': 0.7973032731346197, 'colsample_bylevel': 0.9580885965276406, 'colsample_bytree': 0.8327656424799896, 'reg_alpha': 0.04903043278436087, 'reg_lambda': 0.0387137276240941, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:38:30] {1938} INFO -  at 10349.2s,\testimator xgboost's best error=0.1442,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:38:30] {1748} INFO - iteration 181, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:38:30] {383} INFO - trial 1 config: {'n_estimators': 554, 'max_leaves': 23, 'min_child_weight': 9.314564005655184, 'learning_rate': 0.13682938629334143, 'subsample': 0.7485653917301741, 'colsample_bylevel': 0.9831057356471335, 'colsample_bytree': 0.9270293619355982, 'reg_alpha': 0.3647257114859649, 'reg_lambda': 0.07723657282036472, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:41:42] {1938} INFO -  at 10542.0s,\testimator xgboost's best error=0.1442,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:41:42] {1748} INFO - iteration 182, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:41:42] {383} INFO - trial 1 config: {'n_estimators': 1621, 'max_leaves': 4, 'min_child_weight': 128.0, 'learning_rate': 0.17964494673708697, 'subsample': 0.8460411545390653, 'colsample_bylevel': 0.9330714574081477, 'colsample_bytree': 0.7385019230243812, 'reg_alpha': 0.00659120885453187, 'reg_lambda': 0.019404702355687323, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:49:04] {1938} INFO -  at 10983.3s,\testimator xgboost's best error=0.1442,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:49:04] {1748} INFO - iteration 183, current learner catboost\n",
      "[flaml.tune.tune: 10-09 23:49:04] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.006671961848679559, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:52:20] {1938} INFO -  at 11179.5s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:52:20] {1748} INFO - iteration 184, current learner rf\n",
      "[flaml.tune.tune: 10-09 23:52:20] {383} INFO - trial 1 config: {'n_estimators': 153, 'max_features': 0.390525143683586, 'max_leaves': 26, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-09 23:52:29] {1938} INFO -  at 11188.3s,\testimator rf's best error=0.1720,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:52:29] {1748} INFO - iteration 185, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:52:29] {383} INFO - trial 1 config: {'n_estimators': 1345, 'max_leaves': 6, 'min_child_weight': 10.175781272398414, 'learning_rate': 0.04349698197269903, 'subsample': 0.8300433204453486, 'colsample_bylevel': 0.8189744546007918, 'colsample_bytree': 0.753570297896009, 'reg_alpha': 0.06665689165957213, 'reg_lambda': 0.023636071579886182, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-09 23:59:22] {1938} INFO -  at 11602.1s,\testimator xgboost's best error=0.1442,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-09 23:59:22] {1748} INFO - iteration 186, current learner xgboost\n",
      "[flaml.tune.tune: 10-09 23:59:22] {383} INFO - trial 1 config: {'n_estimators': 668, 'max_leaves': 6, 'min_child_weight': 128.0, 'learning_rate': 0.5651129503229385, 'subsample': 0.7645632258238908, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9119609870639702, 'reg_alpha': 0.036065038125379034, 'reg_lambda': 0.0634095518575073, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:02:25] {1938} INFO -  at 11785.0s,\testimator xgboost's best error=0.1442,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:02:25] {1748} INFO - iteration 187, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:02:25] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.017882203147996406, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:05:15] {1938} INFO -  at 11955.1s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:05:15] {1748} INFO - iteration 188, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:05:15] {383} INFO - trial 1 config: {'n_estimators': 89, 'max_features': 0.6153039394603743, 'max_leaves': 201, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:05:18] {1938} INFO -  at 11957.2s,\testimator extra_tree's best error=0.1729,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:05:18] {1748} INFO - iteration 189, current learner rf\n",
      "[flaml.tune.tune: 10-10 00:05:18] {383} INFO - trial 1 config: {'n_estimators': 72, 'max_features': 0.46222374604319666, 'max_leaves': 36, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:05:23] {1938} INFO -  at 11963.0s,\testimator rf's best error=0.1720,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:05:23] {1748} INFO - iteration 190, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:05:23] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.0941569703418302, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:05:32] {1938} INFO -  at 11971.5s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:05:32] {1748} INFO - iteration 191, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:05:32] {383} INFO - trial 1 config: {'n_estimators': 104, 'max_features': 0.349866810165063, 'max_leaves': 319, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:05:34] {1938} INFO -  at 11973.3s,\testimator extra_tree's best error=0.1729,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:05:34] {1748} INFO - iteration 192, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:05:34] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.115204625817549, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:05:39] {1938} INFO -  at 11978.3s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-10 00:05:39] {1748} INFO - iteration 193, current learner xgboost\n",
      "[flaml.tune.tune: 10-10 00:05:39] {383} INFO - trial 1 config: {'n_estimators': 440, 'max_leaves': 4, 'min_child_weight': 68.53025863627005, 'learning_rate': 0.46417523554443274, 'subsample': 0.6342527174916044, 'colsample_bylevel': 0.9321336284479297, 'colsample_bytree': 0.9343489840339043, 'reg_alpha': 0.0724287356269123, 'reg_lambda': 0.015979629353537653, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:07:38] {1938} INFO -  at 12097.7s,\testimator xgboost's best error=0.1442,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:07:38] {1748} INFO - iteration 194, current learner xgboost\n",
      "[flaml.tune.tune: 10-10 00:07:38] {383} INFO - trial 1 config: {'n_estimators': 2044, 'max_leaves': 14, 'min_child_weight': 62.38952154126177, 'learning_rate': 0.052955664004575395, 'subsample': 0.9603538287776349, 'colsample_bylevel': 0.9840435646073515, 'colsample_bytree': 0.7311823009260751, 'reg_alpha': 0.03319101622048035, 'reg_lambda': 0.09379145619674498, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:19:49] {1938} INFO -  at 12828.6s,\testimator xgboost's best error=0.1440,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:19:49] {1748} INFO - iteration 195, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:19:49] {383} INFO - trial 1 config: {'n_estimators': 159, 'max_features': 0.649216237565041, 'max_leaves': 127, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:19:52] {1938} INFO -  at 12832.1s,\testimator extra_tree's best error=0.1729,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:19:52] {1748} INFO - iteration 196, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:19:52] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.07695467956289141, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:19:58] {1938} INFO -  at 12837.7s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:19:58] {1748} INFO - iteration 197, current learner lgbm\n",
      "[flaml.tune.tune: 10-10 00:19:58] {383} INFO - trial 1 config: {'n_estimators': 432, 'num_leaves': 12, 'min_child_samples': 5, 'learning_rate': 0.12414708840216114, 'log_max_bin': 8, 'colsample_bytree': 0.44713097754576164, 'reg_alpha': 0.0011754888204348985, 'reg_lambda': 0.6134030505559395, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:20:46] {1938} INFO -  at 12886.1s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:20:46] {1748} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:20:46] {383} INFO - trial 1 config: {'n_estimators': 58, 'max_features': 0.33159125438453185, 'max_leaves': 504, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:20:48] {1938} INFO -  at 12887.3s,\testimator extra_tree's best error=0.1729,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:20:48] {1748} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:20:48] {383} INFO - trial 1 config: {'n_estimators': 96, 'max_features': 0.4639767521988556, 'max_leaves': 253, 'criterion': 'gini', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:20:57] {1938} INFO -  at 12896.6s,\testimator extra_tree's best error=0.1701,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:20:57] {1748} INFO - iteration 200, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:20:57] {383} INFO - trial 1 config: {'n_estimators': 64, 'max_features': 0.6884325383639347, 'max_leaves': 127, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:21:06] {1938} INFO -  at 12905.3s,\testimator extra_tree's best error=0.1701,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:21:06] {1748} INFO - iteration 201, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:21:06] {383} INFO - trial 1 config: {'n_estimators': 145, 'max_features': 0.3127022832078791, 'max_leaves': 505, 'criterion': 'gini', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:21:17] {1938} INFO -  at 12916.6s,\testimator extra_tree's best error=0.1689,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:21:17] {1748} INFO - iteration 202, current learner lgbm\n",
      "[flaml.tune.tune: 10-10 00:21:17] {383} INFO - trial 1 config: {'n_estimators': 14853, 'num_leaves': 10, 'min_child_samples': 5, 'learning_rate': 0.02310208574052443, 'log_max_bin': 9, 'colsample_bytree': 0.5112783373908929, 'reg_alpha': 0.008110414105028607, 'reg_lambda': 0.32659845273314325, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:37:24] {1938} INFO -  at 13883.2s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:37:24] {1748} INFO - iteration 203, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:37:24] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.0941569703418302, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:37:39] {1938} INFO -  at 13898.8s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:37:39] {1748} INFO - iteration 204, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:37:39] {383} INFO - trial 1 config: {'n_estimators': 433, 'max_features': 0.3736117443646329, 'max_leaves': 356, 'criterion': 'gini', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:38:16] {1938} INFO -  at 13935.5s,\testimator extra_tree's best error=0.1685,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:38:16] {1748} INFO - iteration 205, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:38:16] {383} INFO - trial 1 config: {'n_estimators': 145, 'max_features': 0.312702283207879, 'max_leaves': 504, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:38:28] {1938} INFO -  at 13947.7s,\testimator extra_tree's best error=0.1685,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:38:28] {1748} INFO - iteration 206, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:38:28] {383} INFO - trial 1 config: {'n_estimators': 261, 'max_features': 0.3057723615767868, 'max_leaves': 446, 'criterion': 'gini', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:38:47] {1938} INFO -  at 13967.0s,\testimator extra_tree's best error=0.1681,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:38:47] {1748} INFO - iteration 207, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:38:47] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.0941569703418302, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-10 00:39:24] {1938} INFO -  at 14003.6s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:39:24] {1748} INFO - iteration 208, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:39:24] {383} INFO - trial 1 config: {'n_estimators': 433, 'max_features': 0.3736117443646329, 'max_leaves': 356, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:40:01] {1938} INFO -  at 14040.9s,\testimator extra_tree's best error=0.1681,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:40:01] {1748} INFO - iteration 209, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:40:01] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.07656841878128254, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-10 00:40:26] {1938} INFO -  at 14065.3s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:40:26] {1748} INFO - iteration 210, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:40:26] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.005312792908071011, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-10 00:40:49] {1938} INFO -  at 14088.6s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:40:49] {1748} INFO - iteration 211, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:40:49] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.005, 'FLAML_sample_size': 720000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-10 00:43:57] {1938} INFO -  at 14276.9s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:43:57] {1748} INFO - iteration 212, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:43:57] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.018642511570516173, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:45:57] {1938} INFO -  at 14396.6s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:45:57] {1748} INFO - iteration 213, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:45:57] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.05251295497953012, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:46:05] {1938} INFO -  at 14404.2s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:46:05] {1748} INFO - iteration 214, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:46:05] {383} INFO - trial 1 config: {'n_estimators': 556, 'max_features': 0.43389323812387937, 'max_leaves': 608, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:47:08] {1938} INFO -  at 14467.7s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:47:08] {1748} INFO - iteration 215, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 00:47:08] {383} INFO - trial 1 config: {'n_estimators': 261, 'max_features': 0.30577236157678667, 'max_leaves': 446, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:47:28] {1938} INFO -  at 14487.4s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:47:28] {1748} INFO - iteration 216, current learner catboost\n",
      "[flaml.tune.tune: 10-10 00:47:28] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.05251295497953012, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 00:47:42] {1938} INFO -  at 14501.4s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:47:42] {1748} INFO - iteration 217, current learner lrl1\n",
      "[flaml.tune.tune: 10-10 00:47:42] {383} INFO - trial 1 config: {'C': 0.10122113739063966, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:48:09] {1938} INFO -  at 14528.6s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:48:09] {1748} INFO - iteration 218, current learner rf\n",
      "[flaml.tune.tune: 10-10 00:48:09] {383} INFO - trial 1 config: {'n_estimators': 217, 'max_features': 0.2661283119369967, 'max_leaves': 18, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:48:16] {1938} INFO -  at 14535.3s,\testimator rf's best error=0.1708,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:48:16] {1748} INFO - iteration 219, current learner rf\n",
      "[flaml.tune.tune: 10-10 00:48:16] {383} INFO - trial 1 config: {'n_estimators': 153, 'max_features': 0.3905251436835859, 'max_leaves': 26, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:48:21] {1938} INFO -  at 14541.0s,\testimator rf's best error=0.1708,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:48:21] {1748} INFO - iteration 220, current learner rf\n",
      "[flaml.tune.tune: 10-10 00:48:21] {383} INFO - trial 1 config: {'n_estimators': 334, 'max_features': 0.31329212961712, 'max_leaves': 5, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:48:29] {1938} INFO -  at 14548.4s,\testimator rf's best error=0.1708,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:48:29] {1748} INFO - iteration 221, current learner rf\n",
      "[flaml.tune.tune: 10-10 00:48:29] {383} INFO - trial 1 config: {'n_estimators': 141, 'max_features': 0.2260646588887855, 'max_leaves': 67, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 00:48:33] {1938} INFO -  at 14552.8s,\testimator rf's best error=0.1695,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:48:33] {1748} INFO - iteration 222, current learner lgbm\n",
      "[flaml.tune.tune: 10-10 00:48:33] {383} INFO - trial 1 config: {'n_estimators': 647, 'num_leaves': 5, 'min_child_samples': 3, 'learning_rate': 0.1203276855079407, 'log_max_bin': 9, 'colsample_bytree': 0.4235016823763597, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.07703482936365054, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 00:49:31] {1938} INFO -  at 14610.3s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 00:49:31] {1748} INFO - iteration 223, current learner xgboost\n",
      "[flaml.tune.tune: 10-10 00:49:31] {383} INFO - trial 1 config: {'n_estimators': 2125, 'max_leaves': 23, 'min_child_weight': 128.0, 'learning_rate': 0.01196086097914623, 'subsample': 0.8562348460284993, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7887994837772533, 'reg_alpha': 0.052273851913646835, 'reg_lambda': 0.2017417984802991, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:04:07] {1938} INFO -  at 15486.4s,\testimator xgboost's best error=0.1440,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:04:07] {1748} INFO - iteration 224, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:04:07] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.017764013158588804, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:04:16] {1938} INFO -  at 15495.3s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:04:16] {1748} INFO - iteration 225, current learner lgbm\n",
      "[flaml.tune.tune: 10-10 01:04:16] {383} INFO - trial 1 config: {'n_estimators': 9920, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.05674415473631505, 'log_max_bin': 9, 'colsample_bytree': 0.43330284934913116, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.4006174393189625, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:12:27] {1938} INFO -  at 15987.0s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:12:27] {1748} INFO - iteration 226, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:12:27] {383} INFO - trial 1 config: {'n_estimators': 130, 'max_features': 0.2997962172195629, 'max_leaves': 53, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:12:33] {1938} INFO -  at 15992.4s,\testimator rf's best error=0.1695,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:12:33] {1748} INFO - iteration 227, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:12:33] {383} INFO - trial 1 config: {'n_estimators': 152, 'max_features': 0.1704665604939064, 'max_leaves': 84, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:12:39] {1938} INFO -  at 15998.5s,\testimator rf's best error=0.1677,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:12:39] {1748} INFO - iteration 228, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:12:39] {383} INFO - trial 1 config: {'n_estimators': 252, 'max_features': 0.23852414697509572, 'max_leaves': 42, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:12:42] {1938} INFO -  at 16001.3s,\testimator rf's best error=0.1677,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:12:42] {1748} INFO - iteration 229, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:12:42] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.09952114805210817, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:12:49] {1938} INFO -  at 16009.1s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:12:49] {1748} INFO - iteration 230, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:12:49] {383} INFO - trial 1 config: {'n_estimators': 92, 'max_features': 0.12182770010977835, 'max_leaves': 168, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:12:53] {1938} INFO -  at 16012.6s,\testimator rf's best error=0.1677,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:12:53] {1748} INFO - iteration 231, current learner xgboost\n",
      "[flaml.tune.tune: 10-10 01:12:53] {383} INFO - trial 1 config: {'n_estimators': 1966, 'max_leaves': 9, 'min_child_weight': 12.53822395125475, 'learning_rate': 0.23445656253799654, 'subsample': 1.0, 'colsample_bylevel': 0.9473041354029622, 'colsample_bytree': 0.6735651180748968, 'reg_alpha': 0.021074466820773734, 'reg_lambda': 0.04360443557939718, 'FLAML_sample_size': 720000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-10 01:18:15] {1938} INFO -  at 16334.9s,\testimator xgboost's best error=0.1440,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:18:15] {1748} INFO - iteration 232, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:18:15] {383} INFO - trial 1 config: {'n_estimators': 101, 'max_features': 0.25293234281853033, 'max_leaves': 42, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:18:19] {1938} INFO -  at 16338.5s,\testimator rf's best error=0.1677,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:18:19] {1748} INFO - iteration 233, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:18:19] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.11412262375222575, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:20:29] {1938} INFO -  at 16469.0s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:20:29] {1748} INFO - iteration 234, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:20:29] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.005, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:21:38] {1938} INFO -  at 16538.0s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:21:38] {1748} INFO - iteration 235, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:21:38] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.010069707499882197, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:21:44] {1938} INFO -  at 16544.1s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:21:44] {1748} INFO - iteration 236, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:21:44] {383} INFO - trial 1 config: {'n_estimators': 230, 'max_features': 0.11488783096225584, 'max_leaves': 168, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:21:53] {1938} INFO -  at 16552.3s,\testimator rf's best error=0.1659,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:21:53] {1748} INFO - iteration 237, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:21:53] {383} INFO - trial 1 config: {'n_estimators': 686, 'max_features': 0.13726616413460188, 'max_leaves': 119, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:22:10] {1938} INFO -  at 16569.8s,\testimator rf's best error=0.1649,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:22:10] {1748} INFO - iteration 238, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:22:10] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.009922601436655172, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:22:15] {1938} INFO -  at 16574.5s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:22:15] {1748} INFO - iteration 239, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:22:15] {383} INFO - trial 1 config: {'n_estimators': 230, 'max_features': 0.11488783096225584, 'max_leaves': 169, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:22:20] {1938} INFO -  at 16579.9s,\testimator rf's best error=0.1649,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:22:20] {1748} INFO - iteration 240, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:22:20] {383} INFO - trial 1 config: {'n_estimators': 414, 'max_features': 0.11234175532517668, 'max_leaves': 149, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:22:33] {1938} INFO -  at 16592.3s,\testimator rf's best error=0.1645,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:22:33] {1748} INFO - iteration 241, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:22:33] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.06141583014445927, 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:22:43] {1938} INFO -  at 16603.0s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:22:43] {1748} INFO - iteration 242, current learner lgbm\n",
      "[flaml.tune.tune: 10-10 01:22:43] {383} INFO - trial 1 config: {'n_estimators': 969, 'num_leaves': 38, 'min_child_samples': 4, 'learning_rate': 0.04898866712317559, 'log_max_bin': 9, 'colsample_bytree': 0.5014771704181215, 'reg_alpha': 0.0016487485010271022, 'reg_lambda': 0.01796311781535687, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:25:17] {1938} INFO -  at 16756.5s,\testimator lgbm's best error=0.1438,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:25:17] {1748} INFO - iteration 243, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:25:17] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.026201073520418543, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-10 01:25:46] {1938} INFO -  at 16785.2s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:25:46] {1748} INFO - iteration 244, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:25:46] {383} INFO - trial 1 config: {'n_estimators': 686, 'max_features': 0.13726616413460188, 'max_leaves': 119, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:26:01] {1938} INFO -  at 16800.7s,\testimator rf's best error=0.1645,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:26:01] {1748} INFO - iteration 245, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:26:01] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.05581489137580452, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-10 01:26:15] {1938} INFO -  at 16814.2s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:26:15] {1748} INFO - iteration 246, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:26:15] {383} INFO - trial 1 config: {'n_estimators': 882, 'max_features': 0.15941378005258533, 'max_leaves': 203, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:26:40] {1938} INFO -  at 16839.6s,\testimator rf's best error=0.1645,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:26:40] {1748} INFO - iteration 247, current learner xgboost\n",
      "[flaml.tune.tune: 10-10 01:26:40] {383} INFO - trial 1 config: {'n_estimators': 4236, 'max_leaves': 20, 'min_child_weight': 128.0, 'learning_rate': 0.0345127634302517, 'subsample': 0.9308955309120248, 'colsample_bylevel': 0.8523609143269087, 'colsample_bytree': 0.7852272465488399, 'reg_alpha': 0.0450462206811414, 'reg_lambda': 0.0768208593913835, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:40:44] {1938} INFO -  at 17683.3s,\testimator xgboost's best error=0.1440,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:40:44] {1748} INFO - iteration 248, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:40:44] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.012801991021121733, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:42:28] {1938} INFO -  at 17787.8s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:42:28] {1748} INFO - iteration 249, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:42:28] {383} INFO - trial 1 config: {'n_estimators': 194, 'max_features': 0.1, 'max_leaves': 109, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:42:33] {1938} INFO -  at 17793.0s,\testimator rf's best error=0.1645,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:42:33] {1748} INFO - iteration 250, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:42:33] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.010291337388218287, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:42:38] {1938} INFO -  at 17797.7s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:42:38] {1748} INFO - iteration 251, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:42:38] {383} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.005756762603127466, 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:42:42] {1938} INFO -  at 17801.4s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-10 01:42:42] {1748} INFO - iteration 252, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:42:42] {383} INFO - trial 1 config: {'n_estimators': 620, 'max_features': 0.1, 'max_leaves': 31, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:42:48] {1938} INFO -  at 17807.8s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:42:48] {1748} INFO - iteration 253, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:42:48] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.008003503338390162, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-10 01:43:06] {1938} INFO -  at 17826.0s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:43:06] {1748} INFO - iteration 254, current learner catboost\n",
      "[flaml.tune.tune: 10-10 01:43:06] {383} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.007103000591571734, 'FLAML_sample_size': 160000}\n",
      "[flaml.automl: 10-10 01:43:17] {1938} INFO -  at 17837.0s,\testimator catboost's best error=0.1449,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:43:17] {1748} INFO - iteration 255, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 01:43:17] {383} INFO - trial 1 config: {'n_estimators': 832, 'max_features': 0.3673711313332253, 'max_leaves': 128, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:43:35] {1938} INFO -  at 17854.9s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:43:35] {1748} INFO - iteration 256, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:43:35] {383} INFO - trial 1 config: {'n_estimators': 414, 'max_features': 0.11810760321564702, 'max_leaves': 147, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:43:36] {1938} INFO -  at 17855.3s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:43:36] {1748} INFO - iteration 257, current learner lrl1\n",
      "[flaml.tune.tune: 10-10 01:43:36] {383} INFO - trial 1 config: {'C': 0.09773076817465907, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:44:04] {1938} INFO -  at 17884.0s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:04] {1748} INFO - iteration 258, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:44:04] {383} INFO - trial 1 config: {'n_estimators': 1134, 'max_features': 0.11643556463429135, 'max_leaves': 115, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:44:06] {1938} INFO -  at 17885.9s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:06] {1748} INFO - iteration 259, current learner lrl1\n",
      "[flaml.tune.tune: 10-10 01:44:06] {383} INFO - trial 1 config: {'C': 0.09464109052286214, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:44:33] {1938} INFO -  at 17912.8s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:33] {1748} INFO - iteration 260, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 01:44:33] {383} INFO - trial 1 config: {'n_estimators': 372, 'max_features': 0.5124609040628737, 'max_leaves': 2891, 'criterion': 'gini', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:44:36] {1938} INFO -  at 17915.5s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:36] {1748} INFO - iteration 261, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 01:44:36] {383} INFO - trial 1 config: {'n_estimators': 1017, 'max_features': 0.505206041719549, 'max_leaves': 2251, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:44:38] {1938} INFO -  at 17918.1s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:38] {1748} INFO - iteration 262, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:44:38] {383} INFO - trial 1 config: {'n_estimators': 339, 'max_features': 0.1, 'max_leaves': 8, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:44:41] {1938} INFO -  at 17920.5s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:41] {1748} INFO - iteration 263, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 01:44:41] {383} INFO - trial 1 config: {'n_estimators': 304, 'max_features': 0.37264665610260944, 'max_leaves': 164, 'criterion': 'gini', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:44:46] {1938} INFO -  at 17925.2s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:46] {1748} INFO - iteration 264, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:44:46] {383} INFO - trial 1 config: {'n_estimators': 809, 'max_features': 0.1, 'max_leaves': 27, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:44:48] {1938} INFO -  at 17927.2s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:48] {1748} INFO - iteration 265, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 01:44:48] {383} INFO - trial 1 config: {'n_estimators': 725, 'max_features': 0.32191480908903225, 'max_leaves': 527, 'criterion': 'gini', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:44:52] {1938} INFO -  at 17931.7s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:52] {1748} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.tune.tune: 10-10 01:44:52] {383} INFO - trial 1 config: {'n_estimators': 426, 'max_features': 0.5848234898617454, 'max_leaves': 702, 'criterion': 'entropy', 'FLAML_sample_size': 40000}\n",
      "[flaml.automl: 10-10 01:44:54] {1938} INFO -  at 17933.7s,\testimator extra_tree's best error=0.1678,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:44:54] {1748} INFO - iteration 267, current learner lrl1\n",
      "[flaml.tune.tune: 10-10 01:44:54] {383} INFO - trial 1 config: {'C': 0.09188500228537068, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:45:22] {1938} INFO -  at 17961.4s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:22] {1748} INFO - iteration 268, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:22] {383} INFO - trial 1 config: {'n_estimators': 475, 'max_features': 0.1347851126674564, 'max_leaves': 36, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:22] {1938} INFO -  at 17961.7s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:22] {1748} INFO - iteration 269, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:22] {383} INFO - trial 1 config: {'n_estimators': 492, 'max_features': 0.1554731391224099, 'max_leaves': 38, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:22] {1938} INFO -  at 17962.0s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:22] {1748} INFO - iteration 270, current learner lrl1\n",
      "[flaml.tune.tune: 10-10 01:45:22] {383} INFO - trial 1 config: {'C': 0.08940969514384722, 'FLAML_sample_size': 720000}\n",
      "[flaml.automl: 10-10 01:45:52] {1938} INFO -  at 17991.5s,\testimator lrl1's best error=0.1599,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:52] {1748} INFO - iteration 271, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:52] {383} INFO - trial 1 config: {'n_estimators': 782, 'max_features': 0.1, 'max_leaves': 26, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:52] {1938} INFO -  at 17991.7s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:52] {1748} INFO - iteration 272, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:52] {383} INFO - trial 1 config: {'n_estimators': 483, 'max_features': 0.1412439304723526, 'max_leaves': 11, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:52] {1938} INFO -  at 17991.8s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:52] {1748} INFO - iteration 273, current learner rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 10-10 01:45:52] {383} INFO - trial 1 config: {'n_estimators': 796, 'max_features': 0.1, 'max_leaves': 87, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:52] {1938} INFO -  at 17992.0s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:52] {1748} INFO - iteration 274, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:52] {383} INFO - trial 1 config: {'n_estimators': 1339, 'max_features': 0.1, 'max_leaves': 12, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:52] {1938} INFO -  at 17992.1s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:52] {1748} INFO - iteration 275, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:52] {383} INFO - trial 1 config: {'n_estimators': 287, 'max_features': 0.125308159461859, 'max_leaves': 79, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:53] {1938} INFO -  at 17992.3s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:53] {1748} INFO - iteration 276, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:53] {383} INFO - trial 1 config: {'n_estimators': 1144, 'max_features': 0.1228875201725817, 'max_leaves': 11, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:53] {1938} INFO -  at 17992.4s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:53] {1748} INFO - iteration 277, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:53] {383} INFO - trial 1 config: {'n_estimators': 336, 'max_features': 0.1, 'max_leaves': 85, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:53] {1938} INFO -  at 17992.5s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:53] {1748} INFO - iteration 278, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:53] {383} INFO - trial 1 config: {'n_estimators': 274, 'max_features': 0.1, 'max_leaves': 12, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:53] {1938} INFO -  at 17992.7s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:53] {1748} INFO - iteration 279, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:53] {383} INFO - trial 1 config: {'n_estimators': 1405, 'max_features': 0.12572621457838054, 'max_leaves': 82, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:53] {1938} INFO -  at 17992.8s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:53] {1748} INFO - iteration 280, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:53] {383} INFO - trial 1 config: {'n_estimators': 457, 'max_features': 0.1, 'max_leaves': 32, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:53] {1938} INFO -  at 17992.9s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:53] {1748} INFO - iteration 281, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:53] {383} INFO - trial 1 config: {'n_estimators': 841, 'max_features': 0.1355317545242152, 'max_leaves': 30, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:53] {1938} INFO -  at 17993.1s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:53] {1748} INFO - iteration 282, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:53] {383} INFO - trial 1 config: {'n_estimators': 382, 'max_features': 0.1, 'max_leaves': 14, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:54] {1938} INFO -  at 17993.2s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:54] {1748} INFO - iteration 283, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:54] {383} INFO - trial 1 config: {'n_estimators': 1007, 'max_features': 0.11169363230497287, 'max_leaves': 68, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:54] {1938} INFO -  at 17993.4s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:54] {1748} INFO - iteration 284, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:54] {383} INFO - trial 1 config: {'n_estimators': 346, 'max_features': 0.12086384718111925, 'max_leaves': 8, 'criterion': 'entropy', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:54] {1938} INFO -  at 17993.5s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:54] {1748} INFO - iteration 285, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:54] {383} INFO - trial 1 config: {'n_estimators': 1111, 'max_features': 0.1, 'max_leaves': 125, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:54] {1938} INFO -  at 17993.7s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:54] {1748} INFO - iteration 286, current learner rf\n",
      "[flaml.tune.tune: 10-10 01:45:54] {383} INFO - trial 1 config: {'n_estimators': 383, 'max_features': 0.1, 'max_leaves': 7, 'criterion': 'gini', 'FLAML_sample_size': 10000}\n",
      "[flaml.automl: 10-10 01:45:54] {1938} INFO -  at 17993.8s,\testimator rf's best error=0.1642,\tbest estimator lgbm's best error=0.1438\n",
      "[flaml.automl: 10-10 01:45:54] {2043} INFO - selected model: LGBMClassifier(colsample_bytree=0.46739000988362633,\n",
      "               learning_rate=0.05272400314432986, max_bin=256,\n",
      "               min_child_samples=4, n_estimators=3100, num_leaves=7,\n",
      "               objective='binary', reg_alpha=0.0009765625,\n",
      "               reg_lambda=0.15861732590335134, verbose=-1)\n",
      "[flaml.automl: 10-10 01:49:16] {2104} INFO - retrain lgbm for 201.9s\n",
      "[flaml.automl: 10-10 01:49:16] {2110} INFO - retrained model: LGBMClassifier(colsample_bytree=0.46739000988362633,\n",
      "               learning_rate=0.05272400314432986, max_bin=256,\n",
      "               min_child_samples=4, n_estimators=2600, num_leaves=7,\n",
      "               objective='binary', reg_alpha=0.0009765625,\n",
      "               reg_lambda=0.15861732590335134, verbose=-1)\n",
      "[flaml.automl: 10-10 01:49:16] {1539} INFO - fit succeeded\n",
      "[flaml.automl: 10-10 01:49:16] {1540} INFO - Time taken to find the best model: 1506.3256299495697\n"
     ]
    }
   ],
   "source": [
    "automl_model = AutoML()\n",
    "automl_model.fit(X_train,y_train,metric='roc_auc', time_budget=5*3600,verbose=2) # ~5 HOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_train_meta_pred = automl_model.predict(X_train_meta)\n",
    "automl_test_pred = automl_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"auto_ml_model.sav\", 'wb') as file:  \n",
    "    pickle.dump(automl_model,file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEVEL2 TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 23) (500000, 23)\n"
     ]
    }
   ],
   "source": [
    "#have npt trained automl yet\n",
    "X_meta = pd.DataFrame(np.column_stack((lgb_train_meta_pred,cat_train_meta_pred,automl_train_meta_pred )))\n",
    "pred_test = pd.DataFrame(np.column_stack((lgb_test_pred,cat_test_pred,automl_test_pred)))\n",
    "print(X_meta .shape, pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta.to_csv('X_meta_2_10102021.csv')\n",
    "pred_test.to_csv('pred_test_2_10102021.csv')\n",
    "y_train_meta.to_csv('y_meta_2_10102021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_meta_tr, X_cv_meta, y_meta_tr, y_cv_meta = train_test_split(X_meta,y_train_meta,test_size=0.1,random_state=2021)\n",
    "lr =LogisticRegression()\n",
    "lr.fit(X_meta_tr,y_meta_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:0.852917\n"
     ]
    }
   ],
   "source": [
    "cv_pred = lr.predict_proba( X_cv_meta)[:,-1]\n",
    "auc = roc_auc_score(y_cv_meta, cv_pred)\n",
    "print(f'auc:{auc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used optuna to tune hyper params\n",
    "lgbm_meta_params={\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbosity': '-1',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 4.355452078897832,\n",
    "     'lambda_l2': 7.380247543873191,\n",
    "     'num_leaves': 30,\n",
    "     'feature_fraction': 0.8515486387805251,\n",
    "     'bagging_fraction': 0.8856322581115998,\n",
    "     'bagging_freq': 3,\n",
    "     'min_child_samples': 548,\n",
    "     'n_estimators': 378,\n",
    "     'max_depth': 5,\n",
    "     'learning_rate': 0.1646686538374961,\n",
    "    'early_stopping_round': 100,\n",
    "    'num_iterations':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.852108\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.85233\n",
      "auc: 0.852330\n",
      "Fold:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.854266\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.854789\n",
      "auc: 0.854789\n",
      "Fold:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.856116\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.856598\n",
      "auc: 0.856598\n",
      "Fold:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.849596\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.849852\n",
      "auc: 0.849852\n",
      "Fold:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.858856\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.859147\n",
      "auc: 0.859147\n",
      "Fold:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.851718\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.851965\n",
      "auc: 0.851965\n",
      "Fold:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.851729\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.852\n",
      "auc: 0.852000\n",
      "Fold:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.852779\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.853129\n",
      "auc: 0.853129\n",
      "Fold:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.851179\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.851863\n",
      "auc: 0.851863\n",
      "Fold:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Ong Yi Kai\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.853927\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.854295\n",
      "auc: 0.854295\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10,random_state=2021,shuffle=True)\n",
    "final_pred = np.zeros(len(pred_test))\n",
    "\n",
    "for fold,(train_idx, val_idx) in enumerate(folds.split(X_meta,y_train_meta)):\n",
    "    print(f'Fold:{fold}')\n",
    "    #create training and CV set for training Lgbm\n",
    "    train = lgb.Dataset(X_meta.iloc[train_idx,:], y_train_meta.iloc[train_idx,:])\n",
    "    CV_meta = lgb.Dataset(X_meta.iloc[val_idx,:], y_train_meta.iloc[val_idx,:])\n",
    "    \n",
    "    #create cat model object and train\n",
    "    model_meta_lgbm = lgb.train(\n",
    "            lgbm_meta_params, \n",
    "            train,\n",
    "            valid_sets=[CV_meta], \n",
    "            verbose_eval=100, \n",
    "            early_stopping_rounds=100)\n",
    "    \n",
    "    #prediction for test and bagging\n",
    "    test_pred_fold = model_meta_lgbm.predict(pred_test)\n",
    "    final_pred += test_pred_fold/folds.n_splits\n",
    "    \n",
    "    #roc_auc_score using training CV for personal satisfaction XD\n",
    "    cv_pred = model_meta_lgbm.predict(X_meta.iloc[val_idx,:])\n",
    "    auc = roc_auc_score(y_train_meta.iloc[val_idx,:],cv_pred)\n",
    "    print(f\"auc: {auc:.6f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(np.column_stack((ID_test,final_pred)))\n",
    "submission[0]=submission[0].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Meta_Model_Pred_{}'.format(time.time()),index=False, header=['id','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
